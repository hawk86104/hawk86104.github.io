import{_ as t}from"./index.aWRnMTX_1741168315107.js";import{_ as n,s as e,p as r,W as o,y as i,C as a}from"./three.FxqAALWt1741168315107.js";import{m as c,e as s,a as l,D as u,o as f}from"./@tresjs.Ea5Oq_-I1741168315107.js";import{_ as p}from"./whiteFloorMesh.vue_vue_type_script_setup_true_lang.7IrD6muy1741168315107.js";import{_ as v}from"./skyBoxAmesh.vue_vue_type_script_setup_true_lang.PiIctW4h1741168315107.js";import{P as d}from"./tweakpane.yDiyAAkA1741168315107.js";import{d as m,a3 as h,a2 as x,w as g,o as y,H as w,u as b,r as C,e as S,j as _,g as P,N as F,f as I,al as j,aj as z,ak as D,m as k,F as N}from"./@vue.NRI7TcgI1741168315107.js";import"./index.kSnl58_g1741168315107.js";import"./@fesjs.vxeGrljA1741168315107.js";import"./vue-router.WwZ4Gmuc1741168315107.js";import"./lodash-es.pklfUAS51741168315107.js";import"./@qlin.yHhFDldE1741168315107.js";import"./pinia.54vgoDms1741168315107.js";import"./@floating-ui.BPbuo5Gx1741168315107.js";import"./@juggle.7yjBMqoW1741168315107.js";import"./chalk.9FGrMJNn1741168315107.js";/* empty css                                 */import"./iconify-icon.BVOVpC8G1741168315107.js";import"./@iconify.dt4P0LGS1741168315107.js";import"./dompurify.rQUea5mq1741168315107.js";import"./postprocessing.hfy6Kqg11741168315107.js";import"./@vueuse.Z8xAfE_A1741168315107.js";import"./utils.6iEAcPmr1741168315107.js";import"./default.vue_vue_type_script_setup_true_lang.TlkKeFuM1741168315107.js";import"./three-mesh-ui.module.MGBYFofo1741168315107.js";!function(t,n){for(var e=E,r=W();;)try{if(104033===parseInt(e(126))/1+parseInt(e(152))/2+-parseInt(e(120))/3*(parseInt(e(135))/4)+parseInt(e(106))/5*(parseInt(e(134))/6)+-parseInt(e(108))/7+parseInt(e(142))/8*(-parseInt(e(109))/9)+parseInt(e(137))/10*(parseInt(e(122))/11))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();var M=function(){var t=!0;return function(n,e){var r=t?function(){if(e){var t=e.apply(n,arguments);return e=null,t}}:function(){};return t=!1,r}}();!function(){M(this,(function(){var t=E,n=new RegExp("function *\\( *\\)"),e=new RegExp("\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","i"),r=R(t(128));n[t(141)](r+t(144))&&e[t(141)](r+"input")?R():r("0")}))()}();var T=function(){var t=!0;return function(n,e){var r=t?function(){if(e){var t=e[E(125)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();T(void 0,(function(){for(var t=E,n=function(){var t,n=E;try{t=Function(n(110)+n(123)+");")()}catch(e){t=window}return t}(),e=n[t(104)]=n[t(104)]||{},r=[t(116),t(115),"info",t(147),t(118),"table",t(111)],o=0;o<r[t(107)];o++){var i=T.constructor.prototype[t(138)](T),a=r[o],c=e[a]||i;i.__proto__=T[t(138)](T),i.toString=c.toString[t(138)](c),e[a]=i}}))();class B{constructor(t,r){var o=E;this[o(102)]=new(n[o(105)])({uniforms:{uTexture:{type:"t",value:null}},vertexShader:o(112),fragmentShader:o(113)+(r||o(124))+o(103),depthTest:!1,depthWrite:!1}),this[o(151)]=new(n[o(139)])(new e(2,2),this[o(102)]),this[o(133)]=new(n[o(149)])(45,window.innerWidth/window[o(117)],1,1e3),this[o(140)]=t,this.scene=new(n[o(131)]),this[o(130)][o(132)](this[o(151)])}blit(t,n){var e=E;this[e(140)][e(119)](n),this[e(102)][e(150)].uTexture[e(114)]=t,this[e(140)][e(121)](this[e(130)],this[e(133)]),this[e(140)][e(119)](null)}}function E(t,n){var e=W();return(E=function(t,n){return e[t-=102]})(t,n)}function R(t){function n(t){var e=E;if("string"==typeof t)return function(t){}[e(129)](e(136))[e(125)](e(146));1!==(""+t/t)[e(107)]||t%20==0?function(){return!0}[e(129)](e(145)+e(143))[e(127)]("action"):function(){return!1}.constructor("debugger").apply(e(148)),n(++t)}try{if(t)return n;n(0)}catch(e){}}function W(){var t=["camera","978msGnpO","63740MHpJex","while (true) {}","900bxBKfO","bind","Mesh","renderer","test","1198328iltzIv","gger","chain","debu","counter","error","stateObject","PerspectiveCamera","uniforms","mesh","277342HkcjQn","material","  \n                }","console","ShaderMaterial","10SkXpSG","length","563423olLAOy","9LzOPHp","return (function() ","trace","\n                varying vec2 vUv;\n\n                void main() {\n                    vUv = uv;\n                    gl_Position = vec4(position.xy, 0.0, 1.0);    \n                }","\n                uniform sampler2D uTexture;\n\n                varying vec2 vUv;\n\n                void main() {\n                    ","value","warn","log","innerHeight","exception","setRenderTarget","6tYYkRz","render","24343kpioot",'{}.constructor("return this")( )',"gl_FragColor = texture2D(uTexture, vUv);","apply","28016epPdVf","call","init","constructor","scene","Scene","add"];return(W=function(){return t})()}const V=A;!function(t,n){const e=A,r=U();for(;;)try{if(690478===parseInt(e(333))/1*(parseInt(e(304))/2)+parseInt(e(283))/3*(-parseInt(e(321))/4)+parseInt(e(332))/5+-parseInt(e(324))/6*(parseInt(e(348))/7)+parseInt(e(302))/8+parseInt(e(307))/9+parseInt(e(347))/10*(parseInt(e(287))/11))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const H=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e.apply(n,arguments);return e=null,t}}:function(){};return t=!1,r}}();function A(t,n){const e=U();return(A=function(t,n){return e[t-=281]})(t,n)}!function(){H(this,(function(){const t=A,n=new RegExp(t(312)),e=new RegExp(t(342),"i"),r=Z("init");n[t(305)](r+t(318))&&e[t(305)](r+"input")?Z():r("0")}))()}();const O=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e[A(341)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();function U(){const t=["info","\n                uniform sampler2D uPrevDepth;\n                uniform float uCameraFarInverse;\n                uniform float uSample;\n                uniform vec2  uScreenSize;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n\n                    vec2 uv = gl_FragCoord.xy / uScreenSize;\n                    float prevRegisteredDepth = texture2D(uPrevDepth, uv).w;\n                    float currentDepth        = abs(vCameraSpacePos.z) * uCameraFarInverse;\n\n                    if(currentDepth <= prevRegisteredDepth) {\n                        discard;\n                    }\n\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }","mesh","warn","uniforms","2332450bqlXfg","3PRNMeZ","getFrontFaceTexture","frontFaceRT","uPrevDepth","action","length","pong","exception","apply","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","traverse","compute","gger","toString","3777210KZRelP","91wwKLJi","WebGLRenderTarget","trace","3fTnCsU","camera","console","frontFaceMaterial","11qJBslI","stateObject","Mesh","\n                uniform float uCameraFarInverse;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n                    float currentDepth = abs(vCameraSpacePos.z) * uCameraFarInverse;\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }","value","blit","Vector2","scene","setRenderTarget","render","FloatType","resultBuffer","prototype","bind","table","3049184bJkUBV","debu","864872siIigg","test","material","2326302tGWFjP","renderer","clear","far","uSample","function *\\( *\\)","add","\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normal;\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }","getBackFaceTexture","texture","blitProgram","chain","ShaderMaterial","clone","4909036BQlFOi","log","DoubleSide","398496bVuSHy","ping","string"];return(U=function(){return t})()}O(void 0,(function(){const t=A,n=function(){let t;try{t=Function('return (function() {}.constructor("return this")( ));')()}catch(n){t=window}return t}(),e=n[t(285)]=n[t(285)]||{},r=[t(322),t(330),t(327),"error",t(340),t(301),t(282)];for(let o=0;o<r[t(338)];o++){const n=O.constructor[t(299)][t(300)](O),i=r[o],a=e[i]||n;n.__proto__=O[t(300)](O),n[t(346)]=a[t(346)][t(300)](a),e[i]=n}}))();class X{constructor(t,e,a){const c=A;this.mesh=t[c(320)](),this.camera=e,this[c(308)]=a,this[c(294)]=new r,this[c(294)][c(313)](this[c(329)]),this[c(317)]=new B(this.renderer),this[c(325)]=new(n[c(281)])(innerWidth,innerHeight,{type:n[c(297)],depthBuffer:!1,stencilBuffer:!1}),this[c(339)]=new(n[c(281)])(innerWidth,innerHeight,{type:n[c(297)],depthBuffer:!1,stencilBuffer:!1}),this[c(335)]=new o(innerWidth,innerHeight,{type:n[c(297)]}),this.frontFaceMaterial=new(n[c(319)])({uniforms:{uCameraFarInverse:{value:1/this[c(284)][c(310)]}},vertexShader:c(314),fragmentShader:c(290),depthTest:!0,depthWrite:!0,side:i}),this[c(306)]=new(n[c(319)])({uniforms:{uScreenSize:{value:new(n[c(293)])(innerWidth,innerHeight)},uPrevDepth:{type:"t",value:this.ping[c(316)]},uCameraFarInverse:{value:1/this[c(284)].far},uSample:{value:0}},vertexShader:"\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normalize((modelMatrix * vec4(normal, 0.0)).xyz);\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }",fragmentShader:c(328),depthTest:!1,depthWrite:!1,side:n[c(323)]}),this[c(329)][c(343)]((t=>{t instanceof n[c(289)]&&(t.material=this.material)}))}[V(344)](t){const e=V;this[e(308)].setRenderTarget(this[e(325)]),this.renderer[e(309)](),this.renderer[e(295)](this.pong),this.renderer.clear(),this[e(329)].traverse((t=>{const r=e;t instanceof n[r(289)]&&(t[r(306)]=this[r(306)])})),this.material[e(331)].uCameraFarInverse[e(291)]=1/this[e(284)][e(310)];for(let n=0;n<t;n++){let t=n%2==0?this[e(325)]:this[e(339)],r=n%2==0?this[e(339)]:this[e(325)];this[e(306)][e(331)][e(336)][e(291)]=t[e(316)],this.material[e(331)][e(311)][e(291)]=n,this[e(308)].autoClear=!1,this[e(308)][e(295)](r),this[e(308)][e(296)](this.scene,this.camera),this[e(308)].autoClear=!0,this[e(317)][e(292)](r[e(316)],t)}this[e(298)]=t%2==0?this[e(325)]:this.pong,this.mesh[e(343)]((t=>{const r=e;t instanceof n[r(289)]&&(t.material=this[r(286)])})),this[e(308)][e(295)](this[e(335)]),this[e(308)].render(this[e(294)],this[e(284)])}[V(315)](){const t=V;return this[t(298)][t(316)]}[V(334)](){const t=V;return this[t(335)][t(316)]}}function Z(t){function n(t){const e=A;if(typeof t===e(326))return function(t){}.constructor("while (true) {}")[e(341)]("counter");1!==(""+t/t)[e(338)]||t%20==0?function(){return!0}.constructor(e(303)+e(345)).call(e(337)):function(){return!1}.constructor(e(303)+e(345))[e(341)](e(288)),n(++t)}try{if(t)return n;n(0)}catch(e){}}const L=J;function G(){const t=["ssrtGlassMesh","exposure","63fBboCC","uCameraPos","reflectionFactor","apply","function *\\( *\\)","uExtinctionFX1","constructor","LinearMipmapLinearFilter","extintionFactor","./draco/","position","uReflectionFactor","Vector3","far","ShaderMaterial","Color","traverse","return (function() ","object","20356TjpHnu","648056eemgtW","Mesh","modelName","__proto__","while (true) {}","extintionCol2Random","extintionColor2","error","debu","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","24LyvIbA","wrapS","uExposure","exception","uniforms","extintionColor1","log","getBackFaceTexture","bind","magFilter","11482247jkpGeS","sub","getObjectByName","value","warn","trace","extintionCol1Random","#fff","prototype","Vector4","2557670nZHjdI","input","ClampToEdgeWrapping","setRenderTarget","length","convertLinearToSRGB","298424bffZCL","3960204tNjGWr","action","autoClear","1LIwqbV","info","string","Vector2","material","uExtintionColor2","Scene","gger","innerWidth","innerHeight","44gUXWKC","clone","525FFmdUg",'{}.constructor("return this")( )',"console","1719695mETcsM","test","toString"];return(G=function(){return t})()}!function(t,n){const e=J,r=G();for(;;)try{if(971564===parseInt(e(276))/1*(parseInt(e(236))/2)+-parseInt(e(288))/3*(-parseInt(e(235))/4)+-parseInt(e(291))/5*(parseInt(e(246))/6)+parseInt(e(256))/7+-parseInt(e(272))/8+-parseInt(e(216))/9*(parseInt(e(266))/10)+-parseInt(e(286))/11*(-parseInt(e(273))/12))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const q=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e[J(219)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();!function(){q(this,(function(){const t=J,n=new RegExp(t(220)),e=new RegExp(t(245),"i"),r=Q("init");n[t(292)](r+"chain")&&e[t(292)](r+t(267))?Q():r("0")}))()}();const Y=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e[J(219)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();Y(void 0,(function(){const t=J;let n;try{n=Function(t(233)+t(289)+");")()}catch(o){n=window}const e=n.console=n[t(290)]||{},r=[t(252),t(260),t(277),t(243),t(249),"table",t(261)];for(let i=0;i<r[t(270)];i++){const n=Y[t(222)][t(264)][t(254)](Y),o=r[i],a=e[o]||n;n[t(239)]=Y[t(254)](Y),n[t(293)]=a.toString[t(254)](a),e[o]=n}}))();const $=[L(234)];function J(t,n){const e=G();return(J=function(t,n){return e[t-=214]})(t,n)}const K=m({__name:L(214),props:{skyBoxTexture:{},modelPath:{},modelName:{},extintionFactor:{default:5},reflectionFactor:{default:1},exposure:{default:0},extintionColor1:{default:"rgb(192,123,25)"},extintionColor2:{default:"rgb(26, 166, 192)"},extintionCol1Random:{type:Boolean,default:!1},extintionCol2Random:{type:Boolean,default:!1}},async setup(t){const e=L;let r,o;const f=t,{map:p}=([r,o]=h((()=>l({map:f.skyBoxTexture}))),r=await r,o(),r);p[e(247)]=n[e(268)],p.wrapT=n[e(268)],p[e(255)]=n[e(223)],p.minFilter=n[e(223)];const{camera:v,renderer:d,scene:m}=c(),C=new(n[e(230)])({uniforms:{uSkybox:{type:"t",value:p},uBackFaceBuffer:{type:"t",value:null},uFrontFaceBuffer:{type:"t",value:null},uCameraFarInverse:{value:1/v[e(259)][e(229)]},uScreenSizeInv:{value:new(n[e(279)])(1/window[e(284)],1/window[e(285)])},uCameraPos:{value:new(n[e(228)])(0,0,0)},uTime:{value:0},uExtintionColor1:{value:new a("#fff")[e(257)](new(n[e(231)])(f.extintionColor1)[e(271)]())},uExtintionColor2:{value:new(n[e(231)])(e(263)).sub(new(n[e(231)])(f.extintionColor2)[e(271)]())},uExtintionFactor:{value:f.extintionFactor},uExposure:{value:f[e(215)]},uReflectionFactor:{value:f.reflectionFactor},uExtinctionFX1:{value:new(n[e(265)])(f[e(262)]?1:0,f[e(241)]?1:0,0,1)}},vertexShader:"varying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\n// NOTE: we don't need the projViewModel matrix, because vWorldSpaceFragPos is already multiplied by the model matrix\n// I'm repeating this comment 5 times because I've lost 2 hours of my life debugging this thing\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nvoid main(){\n\t// NOTE: the multiplication with modelMatrix is required otherwise viewDir in the fragment shader would be incorrect\n\tvWorldSpaceFragPos=(modelMatrix*vec4(position,1.)).xyz;\n\tvWorldSpaceNormal=normalize((modelMatrix*vec4(normal,0.)).xyz);\n\t\n\tgl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.);\n\tvProjViewMatrix=projectionMatrix*viewMatrix;\n\tvViewMatrix=viewMatrix;\n}",fragmentShader:"uniform sampler2D uSkybox;\nuniform sampler2D uBackFaceBuffer;\nuniform sampler2D uFrontFaceBuffer;\n\nuniform vec3 uExtintionColor1;\nuniform vec3 uExtintionColor2;\nuniform float uExtintionFactor;\nuniform float uExposure;\nuniform float uReflectionFactor;\nuniform vec4 uExtinctionFX1;\n\nuniform float uTime;\n\nuniform vec3 uCameraPos;\nuniform vec2 uScreenSizeInv;\nuniform float uCameraFarInverse;\n\nvarying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nconst float PI=3.14159265359;\nconst float e=2.7182818284590;\n\nconst float planeSize=3.;\nconst vec3 planeColor=pow(vec3(202./255.,205./255.,185./255.),vec3(3.));\n\nfloat mod289(float x){return x-floor(x*(1./289.))*289.;}\nvec4 mod289(vec4 x){return x-floor(x*(1./289.))*289.;}\nvec4 perm(vec4 x){return mod289(((x*34.)+1.)*x);}\n\nfloat noise(vec3 p){\n\tvec3 a=floor(p);\n\tvec3 d=p-a;\n\td=d*d*(3.-2.*d);\n\t\n\tvec4 b=a.xxyy+vec4(0.,1.,0.,1.);\n\tvec4 k1=perm(b.xyxy);\n\tvec4 k2=perm(k1.xyxy+b.zzww);\n\t\n\tvec4 c=k2+a.zzzz;\n\tvec4 k3=perm(c);\n\tvec4 k4=perm(c+1.);\n\t\n\tvec4 o1=fract(k3*(1./41.));\n\tvec4 o2=fract(k4*(1./41.));\n\t\n\tvec4 o3=o2*d.z+o1*(1.-d.z);\n\tvec2 o4=o3.yw*d.x+o3.xz*(1.-d.x);\n\t\n\treturn o4.y*d.y+o4.x*(1.-d.y);\n}\n\nvec3 acesFilm(const vec3 x){\n\tconst float a=2.51;\n\tconst float b=.03;\n\tconst float c=2.43;\n\tconst float d=.59;\n\tconst float e=.14;\n\treturn clamp((x*(a*x+b))/(x*(c*x+d)+e),0.,1.);\n}\n\n// gets the skybox color from a given view direction\nvec3 getSkyboxColor(vec3 viewDir){\n\t// skybox coordinates\n\tvec2 skyboxUV=vec2(\n\t\t(atan(viewDir.x,viewDir.z)+PI)/(PI*2.),\n\t\t(asin(viewDir.y)+PI*.5)/(PI)\n\t);\n\t\n\tvec3 col=texture2D(uSkybox,skyboxUV).xyz;\n\tcol=pow(col,vec3(2.2));\n\treturn col;\n}\n\nbool refract2(vec3 v,vec3 n,float ni_over_nt,inout vec3 refracted){\n\tvec3 uv=normalize(v);\n\tfloat dt=dot(uv,n);\n\tfloat discriminant=1.-ni_over_nt*ni_over_nt*(1.-dt*dt);\n\tif(discriminant>0.){\n\t\trefracted=ni_over_nt*(v-n*dt)-n*sqrt(discriminant);\n\t\treturn true;\n\t}\n\t\n\treturn false;\n}\n\nvec3 binarySearchHitPoint(vec3 lastP,vec3 hitP,vec3 rayDir){\n\t\n\tfor(int i=0;i<10;i++){\n\t\tvec3 midP=(lastP+hitP)*.5;\n\t\t\n\t\t// project midP in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(midP,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 midpNDC=projCoord.xy;\n\t\tvec2 midpUV=midpNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,midpUV);\n\t\tfloat depth=backBuffer.w;\n\t\t\n\t\tfloat midpDepth=abs((vViewMatrix*vec4(midP,1.)).z)*uCameraFarInverse;\n\t\tif(midpDepth>depth){\n\t\t\thitP=midP;\n\t\t}else{\n\t\t\tlastP=midP;\n\t\t}\n\t}\n\t\n\treturn hitP;\n}\n\nvec3 getRefractedColor(vec3 refractionDir,vec3 hitPoint,float refractionIndex){\n\t// move the hitpoint inside the mesh with epsilon\n\thitPoint+=refractionDir*.0001;\n\t\n\t// raymarch!\n\tfloat stepSize=.02;\n\tfloat stepMult=1.5;\n\t\n\tvec3 lastP=hitPoint;\n\tvec3 p=hitPoint;\n\tvec3 hitPNormal;\n\tfloat currStepSize=stepSize;\n\tfloat transmissionDistance=0.;\n\tfor(int i=0;i<20;i++){\n\t\tp+=currStepSize*refractionDir;\n\t\t\n\t\t// project p in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 pNDC=projCoord.xy;\n\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,pUV);\n\t\tfloat depth=backBuffer.w;\n\t\tvec3 norm=backBuffer.xyz;\n\t\t\n\t\t// get p depth\n\t\tfloat pDepth=abs((vViewMatrix*vec4(p,1.)).z)*uCameraFarInverse;\n\t\t\n\t\tif(pDepth>depth){\n\t\t\t\n\t\t\tvec3 hitp=binarySearchHitPoint(lastP,p,refractionDir);\n\t\t\tp=hitp;\n\t\t\t\n\t\t\t// ************ get the hitpoint normal\n\t\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\t\tprojCoord.xyz/=projCoord.w;\n\t\t\t\n\t\t\tvec2 pNDC=projCoord.xy;\n\t\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\t\n\t\t\t// get depth at point\n\t\t\thitPNormal=texture2D(uBackFaceBuffer,pUV).xyz;\n\t\t\t// ************ get the hitpoint normal - END\n\t\t\t\n\t\t\tbreak;\n\t\t}\n\t\t\n\t\tlastP=p;\n\t\tcurrStepSize*=stepMult;\n\t}\n\t\n\ttransmissionDistance=length(hitPoint-p);\n\t\n\t// ******************** recalc directions\n\tvec3 outward_normal;\n\tvec3 reflected=reflect(refractionDir,hitPNormal);\n\tfloat ni_over_nt;\n\tvec3 refr;\n\t// vec3 refracted;\n\tfloat reflect_prob;\n\tfloat cosine;\n\t\n\tif(dot(refractionDir,hitPNormal)>0.){\n\t\toutward_normal=-hitPNormal;\n\t\tni_over_nt=refractionIndex;\n\t\tcosine=refractionIndex*dot(refractionDir,hitPNormal);\n\t}else{\n\t\toutward_normal=hitPNormal;\n\t\tni_over_nt=1./refractionIndex;\n\t\tcosine=-dot(refractionDir,hitPNormal);\n\t}\n\t\n\t// if (refract2(refractionDir, outward_normal, ni_over_nt, refracted)) {\n\t\tif(refract2(refractionDir,outward_normal,ni_over_nt,refr)){\n\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\tr0*=r0;\n\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t}else{\n\t\t\treflect_prob=1.;\n\t\t}\n\t\t// ******************** recalc directions - END\n\t\t\n\t\t// ******************** get colors\n\t\tvec3 col;\n\t\tvec3 colrefl;\n\t\tvec3 colrefr;\n\t\t// if(refracted.y < 0.0) {\n\t\t\tif(refr.y<0.){\n\t\t\t\t// float t = p.y / abs(refracted.y);\n\t\t\t\t// vec3 planeHitP = p + refracted * t;\n\t\t\t\tfloat t=p.y/abs(refr.y);\n\t\t\t\tvec3 planeHitP=p+refr*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefr=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t}\n\t\t\t\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=p.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=p+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefl=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tcol=colrefl*(reflect_prob*uReflectionFactor)+colrefr*(1.-reflect_prob);\n\t\t\t// ******************** get colors\n\t\t\t\n\t\t\tvec3 transm=vec3(1.);\n\t\t\t// const int steps = 8;\n\t\t\tconst int steps=15;\n\t\t\tfloat step=transmissionDistance/float(steps);\n\t\t\tfloat fc=uExtintionFactor*.07;\n\t\t\t\n\t\t\t// raymarching transmission color\n\t\t\t\n\t\t\t// float noiseStrength = 0.8;\n\t\t\tfloat noiseSpeed=.5;\n\t\t\tfloat noiseTimeSpeed=.5;\n\t\t\t\n\t\t\tfor(int i=0;i<steps;i++){\n\t\t\t\tvec3 np=hitPoint+refractionDir*float(i)*step;\n\t\t\t\t\n\t\t\t\tvec3 nnp=np;\n\t\t\t\tvec3 w=normalize(np-vec3(.75,1.5,0.));\n\t\t\t\tvec3 u=vec3(0.,0.,1.);\n\t\t\t\t// vec3 timeOffset = uTime * normalize(np - vec3(0.75, 1.5, 0.0));\n\t\t\t\tvec3 timeOffset=cos(uTime)*w+sin(uTime)*u;\n\t\t\t\tfloat colorNoiseX=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed);\n\t\t\t\tfloat colorNoiseY=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(15.3278,125.19879,0.));\n\t\t\t\tfloat colorNoiseZ=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(2.6008,78.19879,543.12993));\n\t\t\t\t\n\t\t\t\tfloat targ=length(nnp*.8*uExtinctionFX1.w-vec3(.75,1.5,0.));\n\t\t\t\tfloat targAperture=.25;\n\t\t\t\t\n\t\t\t\t// wave raymarch\n\t\t\t\tif(uExtinctionFX1.z>.5){\n\t\t\t\t\tnnp=np+sin(np.x*2.5+uTime*1.5)*.3;\n\t\t\t\t\ttarg=nnp.y-.85*uExtinctionFX1.w;\n\t\t\t\t}else{\n\t\t\t\t\tnnp=np+vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*1.05;\n\t\t\t\t\tvec3 diff=nnp-vec3(3.3,4.5,0.);\n\t\t\t\t\tfloat angle=(atan(diff.x,diff.y)+PI)/(PI*2.);\n\t\t\t\t\ttarg=length(diff)+sin(angle*32.*PI+uTime*1.5)*.4;\n\t\t\t\t\ttarg*=.475;\n\t\t\t\t\ttargAperture=.5+colorNoiseX*.75;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// what's the color at np?\n\t\t\t\tvec3 col1=uExtintionColor1;\n\t\t\t\tvec3 col2=uExtintionColor2;\n\t\t\t\tif(uExtinctionFX1.x>.5){\n\t\t\t\t\tcol1=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\tif(uExtinctionFX1.y>.5){\n\t\t\t\t\tcol2=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(targ<1.){\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*col2*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ>1.&&targ<1.+targAperture){\n\t\t\t\t\tfloat t=(targ-1.)/targAperture;\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*(col1*t+col2*(1.-t))*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ<(1.+targAperture)*1.85){\n\t\t\t\t\ttransm*=exp(-step*col1*fc);\n\t\t\t\t\t\n\t\t\t\t}else{\n\t\t\t\t\t// transm = (col1) * targAperture;\n\t\t\t\t\t// transm *= exp(-step * col1 * uExtintionFactor);\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// return col * uExtintionColor2 * transm;\n\t\t\tcol*=transm;\n\t\t\t\n\t\t\treturn col;\n\t\t}\n\t\t\n\t\tvoid main(){\n\t\t\tvec2 screenUV=gl_FragCoord.xy*uScreenSizeInv;\n\t\t\t\n\t\t\tvec3 viewDir=normalize(vWorldSpaceFragPos-uCameraPos);\n\t\t\tvec3 normal=vWorldSpaceNormal;\n\t\t\tfloat refractionIndex=1.5;\n\t\t\t\n\t\t\tvec3 outward_normal;\n\t\t\tvec3 reflected=reflect(viewDir,normal);\n\t\t\tfloat ni_over_nt;\n\t\t\tvec3 refracted;\n\t\t\tfloat reflect_prob;\n\t\t\tfloat cosine;\n\t\t\t\n\t\t\tif(dot(viewDir,normal)>0.){\n\t\t\t\toutward_normal=-normal;\n\t\t\t\tni_over_nt=refractionIndex;\n\t\t\t\tcosine=refractionIndex*dot(viewDir,normal);\n\t\t\t}else{\n\t\t\t\toutward_normal=normal;\n\t\t\t\tni_over_nt=1./refractionIndex;\n\t\t\t\tcosine=-dot(viewDir,normal);\n\t\t\t}\n\t\t\t\n\t\t\tif(refract2(viewDir,outward_normal,ni_over_nt,refracted)){\n\t\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\t\tr0*=r0;\n\t\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t\t}else{\n\t\t\t\treflect_prob=1.;\n\t\t\t}\n\t\t\t\n\t\t\tvec3 reflectedCol;\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=vWorldSpaceFragPos.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=vWorldSpaceFragPos+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\treflectedCol=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tvec3 col=reflectedCol*reflect_prob*uReflectionFactor+getRefractedColor(refracted,vWorldSpaceFragPos,refractionIndex)*(1.-reflect_prob);\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.0, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.15, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.35, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333;\n\t\t\t\n\t\t\t// col = getRefractedColor(refracted, vWorldSpaceFragPos) * (1.0 - reflect_prob);\n\t\t\t// vec3 col = getRefractedColor(refracted, vWorldSpaceFragPos);\n\t\t\t// col = getSkyboxColor(reflected) * reflect_prob * 1.0;\n\t\t\t\n\t\t\t// vec3 col = viewDir;\n\t\t\t// gl_FragColor = vec4(col, 1.0);\n\t\t\t// return;\n\t\t\t\n\t\t\tcol*=pow(2.,uExposure);\n\t\t\tcol=acesFilm(col);\n\t\t\tcol=pow(col,vec3(1./2.2));\n\t\t\t\n\t\t\tgl_FragColor=vec4(col,1.);\n\t\t\t// gl_FragColor = vec4(getSkyboxColor(viewDir), 1.0) * 0.5 + vec4(viewDir * 0.5 + 0.5, 1.0);\n\t\t}"}),{nodes:S}=([r,o]=h((()=>u(f.modelPath,{draco:!0,decoderPath:e(225)}))),r=await r,o(),r),_=S[e(282)][e(258)](f[e(238)]),P=new X(_,v.value,d[e(259)]),F=null==_?void 0:_[e(287)]();null==F||F[e(232)]((t=>{const r=e;t instanceof n[r(237)]&&(t.material=C,t[r(280)].side=i)}));const{onAfterLoop:I}=s();return I((({elapsed:t})=>{const n=e;_&&C&&(C[n(250)][n(217)].value=v[n(259)][n(226)][n(287)](),C.uniforms.uTime[n(259)]=t,P.compute(6),C[n(250)].uBackFaceBuffer[n(259)]=P[n(253)](),C.uniforms.uFrontFaceBuffer[n(259)]=P.getFrontFaceTexture(),d[n(259)][n(269)](null),d[n(259)][n(275)]=!1)})),x((()=>{const t=e;f[t(224)]&&(C.uniforms.uExtintionFactor[t(259)]=f.extintionFactor),f.reflectionFactor&&(C[t(250)][t(227)].value=f[t(218)]),f.exposure&&(C[t(250)][t(248)][t(259)]=f[t(215)]),f[t(251)]&&(C[t(250)].uExtintionColor1[t(259)]=new(n[t(231)])(t(263))[t(257)](new(n[t(231)])(f[t(251)])[t(271)]())),f[t(242)]&&(C[t(250)][t(281)][t(259)]=new(n[t(231)])(t(263))[t(257)](new(n[t(231)])(f[t(242)])[t(271)]())),f[t(262)]&&(C[t(250)][t(248)].value=f[t(215)])})),g((()=>f.extintionCol1Random),(t=>{const n=e;C[n(250)].uExtinctionFX1[n(259)].x=t?1:0}),{immediate:!0}),g((()=>f.extintionCol2Random),(t=>{const n=e;C.uniforms[n(221)][n(259)].y=t?1:0}),{immediate:!0}),(t,n)=>(y(),w("primitive",{object:b(F)},null,8,$))}});function Q(t){function n(t){const e=J;if(typeof t===e(278))return function(t){}[e(222)](e(240))[e(219)]("counter");1!==(""+t/t).length||t%20==0?function(){return!0}[e(222)](e(244)+e(283)).call(e(274)):function(){return!1}[e(222)]("debu"+e(283))[e(219)]("stateObject"),n(++t)}try{if(t)return n;n(0)}catch(e){}}function tt(){const t=["rgb(192,123,25)","曝光系数","2087316SjreUU","error","__proto__","reflectionFactor","954099kxdxWZ","console","call","apply","test","string","extintionColor2","178836CwTAiy","gger","31340akOffg","1358064BcfVPn","2585164fsnlou","10vLgSct","#201919","ssrtGlass","exception","https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/images/skyBox/workshop_blur.jpg","log","action","toString","length","extintionCol1Random","6245456bsLIGJ","stateObject","消光系数","extintionCol2Random","extintionColor1","while (true) {}","bind","消光颜色二","statue","rgb(26, 166, 192)","ACESFilmicToneMapping","312dXsrlX","warn","exposure","debu","prototype","反射系数","return (function() ",'{}.constructor("return this")( )',"随机色2","addBinding","随机色1","消光颜色一","constructor","18783jcOFDR","table","init","chain"];return(tt=function(){return t})()}const nt=ot;!function(t,n){const e=ot,r=tt();for(;;)try{if(688453===-parseInt(e(482))/1+-parseInt(e(478))/2+-parseInt(e(436))/3+parseInt(e(437))/4*(-parseInt(e(438))/5)+parseInt(e(459))/6*(-parseInt(e(433))/7)+-parseInt(e(448))/8+parseInt(e(472))/9*(parseInt(e(435))/10))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const et=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e[ot(485)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();!function(){et(this,(function(){const t=ot,n=new RegExp("function *\\( *\\)"),e=new RegExp("\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","i"),r=at(t(474));n[t(486)](r+t(475))&&e[t(486)](r+"input")?at():r("0")}))()}();const rt=function(){let t=!0;return function(n,e){const r=t?function(){if(e){const t=e[ot(485)](n,arguments);return e=null,t}}:function(){};return t=!1,r}}();function ot(t,n){const e=tt();return(ot=function(t,n){return e[t-=431]})(t,n)}rt(void 0,(function(){const t=ot;let n;try{n=Function(t(465)+t(466)+");")()}catch(o){n=window}const e=n[t(483)]=n[t(483)]||{},r=[t(443),t(460),"info",t(479),t(441),t(473),"trace"];for(let i=0;i<r.length;i++){const n=rt[t(471)][t(463)].bind(rt),o=r[i],a=e[o]||n;n[t(480)]=rt[t(454)](rt),n[t(445)]=a.toString[t(454)](a),e[o]=n}}))();const it=m({__name:nt(440),setup(e){const r=nt,o={clearColor:r(439),windowSize:!0,toneMapping:n[r(458)],toneMappingExposure:.8},i=C({size:[20,20],color:"#cbcb96",shadowColor:"#b8b59e",edge:.35}),a=C({extintionFactor:5,reflectionFactor:1,exposure:0,extintionColor1:r(476),extintionColor2:r(457),extintionCol1Random:!1,extintionCol2Random:!1}),c=new d({title:"参数"});return c[r(468)](a,"extintionFactor",{label:r(450),min:0,max:10,step:.1}),c[r(468)](a,r(481),{label:r(464),min:0,max:2,step:.1}),c[r(468)](a,r(461),{label:r(477),min:-1,max:1,step:.1}),c.addBinding(a,r(452),{label:r(470)}),c.addBinding(a,r(432),{label:r(455)}),c[r(468)](a,r(447),{label:r(469)}),c[r(468)](a,r(451),{label:r(467)}),(n,e)=>{const c=r,s=S("TresCanvas");return y(),w(N,null,[_(b(t)),_(s,z(D(o)),{default:P((()=>[e[0]||(e[0]=F("TresPerspectiveCamera",{position:[0,8,-13],fov:45,near:.1,far:1e3,"look-at":[0,0,0]},null,-1)),_(b(f),{enableDamping:""}),e[1]||(e[1]=F("TresAmbientLight",{intensity:10},null,-1)),(y(),I(j,null,{default:P((()=>[_(p,z(D(i)),null,16)])),_:1})),(y(),I(j,null,{default:P((()=>[_(K,k({scale:2},a,{modelPath:"https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/model/eCommerce/guanYu.glb",modelName:c(456),skyBoxTexture:c(442)}),null,16)])),_:1})),(y(),I(j,null,{default:P((()=>[_(v,{texture:c(442)})])),_:1}))])),_:1},16)],64)}}});function at(t){function n(t){const e=ot;if(typeof t===e(431))return function(t){}.constructor(e(453)).apply("counter");1!==(""+t/t)[e(446)]||t%20==0?function(){return!0}[e(471)](e(462)+e(434))[e(484)](e(444)):function(){return!1}.constructor(e(462)+e(434)).apply(e(449)),n(++t)}try{if(t)return n;n(0)}catch(e){}}export{it as default};
