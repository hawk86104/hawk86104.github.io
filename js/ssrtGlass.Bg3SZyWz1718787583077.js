import{_ as t}from"./index.-hwd2uJC1718787583077.js";import{k as e,a5 as n,o as r,j as o,C as i}from"./three.OZpCYxlY1718787583077.js";import{a,r as c,N as l,b as s,d as u}from"./@tresjs.yMGhEK7G1718787583077.js";import{_ as f}from"./whiteFloorMesh.vue_vue_type_script_setup_true_lang.7_H3IJjg1718787583077.js";import{_ as p}from"./skyBoxAmesh.vue_vue_type_script_setup_true_lang.lNMSjlmE1718787583077.js";import{P as v}from"./tweakpane.qqn77PB81718787583077.js";import{d,a3 as m,a2 as h,w as x,o as g,D as y,u as w,r as b,e as C,j as S,g as _,f as F,al as P,aj as I,ak as D,m as j,F as z,J as k}from"./@vue.CpOXM7bB1718787583077.js";import"./default.vue_vue_type_script_setup_true_lang.PLtwinxK1718787583077.js";import"./@fesjs.BvrsBDNW1718787583077.js";import"./vue-router.2IN93cQd1718787583077.js";import"./lodash-es.nFpJXAf-1718787583077.js";import"./@vueuse.jAwx0y-e1718787583077.js";import"./@qlin.yHhFDldE1718787583077.js";import"./pinia.jgDkRZDw1718787583077.js";import"./@floating-ui.BPbuo5Gx1718787583077.js";import"./@juggle.7yjBMqoW1718787583077.js";function N(){var t=["mesh","input","__proto__","string","3206720eYFiST","constructor","innerWidth","counter","6NqUidp","PlaneGeometry","prototype","402321yDpEAa","toString","\n                varying vec2 vUv;\n\n                void main() {\n                    vUv = uv;\n                    gl_Position = vec4(position.xy, 0.0, 1.0);    \n                }","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","78IQCosM","91936wNtbxS","Scene","setRenderTarget","apply","\n                uniform sampler2D uTexture;\n\n                varying vec2 vUv;\n\n                void main() {\n                    ","console","length","test","18HhWgVC","debu","  \n                }","gl_FragColor = texture2D(uTexture, vUv);","camera","gger","call","renderer","innerHeight","scene","1622782LqNHkr","error",'{}.constructor("return this")( )',"return (function() ","function *\\( *\\)","7742HjkvRt","stateObject","Mesh","uTexture","bind","render","warn","material","init","add","uniforms","730705LfudQn","blit","1131828GEjdVb","PerspectiveCamera","exception"];return(N=function(){return t})()}var B=T;!function(t,e){for(var n=T,r=N();;)try{if(159743===parseInt(n(313))/1*(parseInt(n(289))/2)+-parseInt(n(285))/3+-parseInt(n(271))/4+-parseInt(n(269))/5*(parseInt(n(282))/6)+-parseInt(n(308))/7+parseInt(n(290))/8+-parseInt(n(298))/9*(-parseInt(n(278))/10))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();var E=function(){var t=!0;return function(e,n){var r=t?function(){if(n){var t=n[T(293)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function T(t,e){var n=N();return(T=function(t,e){return n[t-=259]})(t,e)}!function(){E(this,(function(){var t=T,e=new RegExp(t(312)),n=new RegExp(t(288),"i"),r=W(t(266));e.test(r+"chain")&&n[t(297)](r+t(275))?W():r("0")}))()}();var M=function(){var t=!0;return function(e,n){var r=t?function(){if(n){var t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();M(void 0,(function(){for(var t=T,e=function(){var t,e=T;try{t=Function(e(311)+e(310)+");")()}catch(n){t=window}return t}(),n=e[t(295)]=e[t(295)]||{},r=["log",t(264),"info",t(309),t(273),"table","trace"],o=0;o<r[t(296)];o++){var i=M.constructor[t(284)][t(262)](M),a=r[o],c=n[a]||i;i[t(276)]=M[t(262)](M),i[t(286)]=c[t(286)].bind(c),n[a]=i}}))();class R{constructor(t,r){var o=T;this.material=new e({uniforms:{uTexture:{type:"t",value:null}},vertexShader:o(287),fragmentShader:o(294)+(r||o(301))+o(300),depthTest:!1,depthWrite:!1}),this[o(274)]=new(n[o(260)])(new(n[o(283)])(2,2),this[o(265)]),this[o(302)]=new(n[o(272)])(45,window[o(280)]/window[o(306)],1,1e3),this[o(305)]=t,this.scene=new(n[o(291)]),this[o(307)][o(267)](this[o(274)])}[B(270)](t,e){var n=B;this.renderer[n(292)](e),this[n(265)][n(268)][n(261)].value=t,this.renderer[n(263)](this[n(307)],this[n(302)]),this[n(305)][n(292)](null)}}function W(t){function e(t){var n=T;if(typeof t===n(277))return function(t){}[n(279)]("while (true) {}")[n(293)](n(281));1!==(""+t/t)[n(296)]||t%20==0?function(){return!0}[n(279)]("debu"+n(303))[n(304)]("action"):function(){return!1}[n(279)](n(299)+n(303))[n(293)](n(259)),e(++t)}try{if(t)return e;e(0)}catch(n){}}const V=X;!function(t,e){const n=X,r=A();for(;;)try{if(983150===parseInt(n(423))/1+parseInt(n(449))/2+parseInt(n(457))/3*(-parseInt(n(466))/4)+-parseInt(n(455))/5+-parseInt(n(436))/6+parseInt(n(425))/7*(parseInt(n(475))/8)+parseInt(n(479))/9)break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const H=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[X(452)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function A(){const t=["DoubleSide","38364tnBfhC","Mesh","uSample","console","render","texture","test","far","autoClear","488nfwiQR","toString","function *\\( *\\)","debu","pong","prototype","\n                uniform sampler2D uPrevDepth;\n                uniform float uCameraFarInverse;\n                uniform float uSample;\n                uniform vec2  uScreenSize;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n\n                    vec2 uv = gl_FragCoord.xy / uScreenSize;\n                    float prevRegisteredDepth = texture2D(uPrevDepth, uv).w;\n                    float currentDepth        = abs(vCameraSpacePos.z) * uCameraFarInverse;\n\n                    if(currentDepth <= prevRegisteredDepth) {\n                        discard;\n                    }\n\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }","WebGLRenderTarget","table","8HTffpS","compute","material","setRenderTarget","15586551OiEsqI","while (true) {}","FloatType","value","scene","gger","traverse","mesh","170873mxQjRP","clear","2098873qnaIld","ping","bind","exception","error","blitProgram","getBackFaceTexture","length","frontFaceMaterial","uPrevDepth","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","531876RcXqYA","stateObject","resultBuffer","blit","\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normal;\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }","uniforms","frontFaceRT","\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normalize((modelMatrix * vec4(normal, 0.0)).xyz);\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }","input","action","ShaderMaterial","call","camera","1066996YBXuLx","FrontSide","log","apply","renderer","constructor","520585hAmLky"];return(A=function(){return t})()}!function(){H(this,(function(){const t=X,e=new RegExp(t(468)),n=new RegExp(t(435),"i"),r=Z("init");e[t(463)](r+"chain")&&n[t(463)](r+t(444))?Z():r("0")}))()}();const U=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();U(void 0,(function(){const t=X;let e;try{e=Function('return (function() {}.constructor("return this")( ));')()}catch(o){e=window}const n=e[t(460)]=e.console||{},r=[t(451),"warn","info",t(429),t(428),t(474),"trace"];for(let i=0;i<r[t(432)];i++){const e=U.constructor[t(471)][t(427)](U),o=r[i],a=n[o]||e;e.__proto__=U[t(427)](U),e[t(467)]=a[t(467)].bind(a),n[o]=e}}))();class O{constructor(t,i,a){const c=X;this.mesh=t.clone(),this[c(448)]=i,this.renderer=a,this[c(419)]=new r,this[c(419)].add(this[c(422)]),this[c(430)]=new R(this[c(453)]),this[c(426)]=new(n[c(473)])(innerWidth,innerHeight,{type:n[c(481)],depthBuffer:!1,stencilBuffer:!1}),this[c(470)]=new(n[c(473)])(innerWidth,innerHeight,{type:n[c(481)],depthBuffer:!1,stencilBuffer:!1}),this[c(442)]=new(n[c(473)])(innerWidth,innerHeight,{type:n[c(481)]}),this.frontFaceMaterial=new(n[c(446)])({uniforms:{uCameraFarInverse:{value:1/this[c(448)][c(464)]}},vertexShader:c(440),fragmentShader:"\n                uniform float uCameraFarInverse;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n                    float currentDepth = abs(vCameraSpacePos.z) * uCameraFarInverse;\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }",depthTest:!0,depthWrite:!0,side:n[c(450)]}),this.material=new e({uniforms:{uScreenSize:{value:new o(innerWidth,innerHeight)},uPrevDepth:{type:"t",value:this[c(426)][c(462)]},uCameraFarInverse:{value:1/this[c(448)].far},uSample:{value:0}},vertexShader:c(443),fragmentShader:c(472),depthTest:!1,depthWrite:!1,side:n[c(456)]}),this.mesh[c(421)]((t=>{const e=c;t instanceof n[e(458)]&&(t[e(477)]=this[e(477)])}))}[V(476)](t){const e=V;this[e(453)][e(478)](this[e(426)]),this[e(453)].clear(),this.renderer.setRenderTarget(this[e(470)]),this[e(453)][e(424)](),this[e(422)][e(421)]((t=>{t instanceof n[e(458)]&&(t.material=this.material)})),this[e(477)][e(441)].uCameraFarInverse[e(418)]=1/this[e(448)][e(464)];for(let n=0;n<t;n++){let t=n%2==0?this.ping:this[e(470)],r=n%2==0?this[e(470)]:this[e(426)];this[e(477)][e(441)][e(434)][e(418)]=t[e(462)],this[e(477)][e(441)][e(459)][e(418)]=n,this[e(453)][e(465)]=!1,this[e(453)][e(478)](r),this[e(453)][e(461)](this[e(419)],this[e(448)]),this.renderer[e(465)]=!0,this[e(430)][e(439)](r[e(462)],t)}this[e(438)]=t%2==0?this.ping:this.pong,this[e(422)].traverse((t=>{const r=e;t instanceof n[r(458)]&&(t.material=this[r(433)])})),this[e(453)].setRenderTarget(this.frontFaceRT),this.renderer[e(461)](this.scene,this.camera)}[V(431)](){const t=V;return this.resultBuffer[t(462)]}getFrontFaceTexture(){const t=V;return this[t(442)][t(462)]}}function X(t,e){const n=A();return(X=function(t,e){return n[t-=418]})(t,e)}function Z(t){function e(t){const n=X;if("string"==typeof t)return function(t){}.constructor(n(480)).apply("counter");1!==(""+t/t).length||t%20==0?function(){return!0}[n(454)]("debugger")[n(447)](n(445)):function(){return!1}[n(454)](n(469)+n(420))[n(452)](n(437)),e(++t)}try{if(t)return e;e(0)}catch(n){}}const Y=Q;!function(t,e){const n=Q,r=$();for(;;)try{if(636001===-parseInt(n(265))/1*(parseInt(n(267))/2)+-parseInt(n(260))/3+parseInt(n(275))/4*(-parseInt(n(226))/5)+parseInt(n(214))/6*(parseInt(n(244))/7)+parseInt(n(263))/8+parseInt(n(262))/9*(-parseInt(n(211))/10)+parseInt(n(219))/11)break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const q=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();!function(){q(this,(function(){const t=Q,e=new RegExp("function *\\( *\\)"),n=new RegExp("\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","i"),r=K(t(206));e[t(215)](r+t(239))&&n[t(215)](r+t(249))?K():r("0")}))()}();const L=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();L(void 0,(function(){const t=Q;let e;try{e=Function(t(208)+'{}.constructor("return this")( ));')()}catch(o){e=window}const n=e[t(227)]=e[t(227)]||{},r=[t(258),"warn",t(248),t(271),t(243),"table",t(212)];for(let i=0;i<r.length;i++){const e=L[t(251)][t(199)][t(270)](L),o=r[i],a=n[o]||e;e[t(269)]=L[t(270)](L),e[t(203)]=a[t(203)].bind(a),n[o]=e}}))();const G=[Y(280)];function $(){const t=["call","skyBoxTexture","object","uniforms","prototype","./draco/","rgb(26, 166, 192)","uExtinctionFX1","toString","extintionColor2","getObjectByName","init","uTime","return (function() ","convertLinearToSRGB","uExtintionColor1","8990tfvBvt","trace","extintionFactor","6156984geeBxL","test","modelName","ShaderMaterial","extintionCol2Random","14370114IBBDOB","getFrontFaceTexture","stateObject","innerWidth","Vector3","Scene","innerHeight","5UWIZUg","console","gger","position","Color","length","uFrontFaceBuffer","compute","Mesh","value","uExposure","uReflectionFactor","extintionColor1","chain","material","#fff","action","exception","7YCVbpO","sub","exposure","side","info","input","clone","constructor","primitive","autoClear","uCameraPos","LinearMipmapLinearFilter","string","ClampToEdgeWrapping","log","debu","3624588KNtyUo","traverse","9189kYESCq","9174032iZbWEA","extintionCol1Random","126TbbSMn","counter","8286cWMLCY","reflectionFactor","__proto__","bind","error","FrontSide","rgb(192,123,25)","magFilter","780792HIxDMn","uExtintionColor2","Vector4"];return($=function(){return t})()}function Q(t,e){const n=$();return(Q=function(t,e){return n[t-=198]})(t,e)}const J=d({__name:"ssrtGlassMesh",props:{skyBoxTexture:{},modelPath:{},modelName:{},extintionFactor:{default:5},reflectionFactor:{default:1},exposure:{default:0},extintionColor1:{default:Y(273)},extintionColor2:{default:Y(201)},extintionCol1Random:{type:Boolean,default:!1},extintionCol2Random:{type:Boolean,default:!1}},async setup(t){const e=Y;let r,u;const f=t,{map:p}=([r,u]=m((()=>l({map:f[e(279)]}))),r=await r,u(),r);p.wrapS=n[e(257)],p.wrapT=n[e(257)],p[e(274)]=n[e(255)],p.minFilter=n[e(255)];const{camera:v,renderer:d,scene:b}=a(),C=new(n[e(217)])({uniforms:{uSkybox:{type:"t",value:p},uBackFaceBuffer:{type:"t",value:null},uFrontFaceBuffer:{type:"t",value:null},uCameraFarInverse:{value:1/v[e(235)].far},uScreenSizeInv:{value:new o(1/window[e(222)],1/window[e(225)])},uCameraPos:{value:new(n[e(223)])(0,0,0)},uTime:{value:0},uExtintionColor1:{value:new i(e(241))[e(245)](new(n[e(230)])(f[e(238)])[e(209)]())},uExtintionColor2:{value:new(n[e(230)])(e(241))[e(245)](new i(f.extintionColor2)[e(209)]())},uExtintionFactor:{value:f.extintionFactor},uExposure:{value:f[e(246)]},uReflectionFactor:{value:f[e(268)]},uExtinctionFX1:{value:new(n[e(277)])(f[e(264)]?1:0,f[e(218)]?1:0,0,1)}},vertexShader:"varying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\n// NOTE: we don't need the projViewModel matrix, because vWorldSpaceFragPos is already multiplied by the model matrix\n// I'm repeating this comment 5 times because I've lost 2 hours of my life debugging this thing\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nvoid main(){\n\t// NOTE: the multiplication with modelMatrix is required otherwise viewDir in the fragment shader would be incorrect\n\tvWorldSpaceFragPos=(modelMatrix*vec4(position,1.)).xyz;\n\tvWorldSpaceNormal=normalize((modelMatrix*vec4(normal,0.)).xyz);\n\t\n\tgl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.);\n\tvProjViewMatrix=projectionMatrix*viewMatrix;\n\tvViewMatrix=viewMatrix;\n}",fragmentShader:"uniform sampler2D uSkybox;\nuniform sampler2D uBackFaceBuffer;\nuniform sampler2D uFrontFaceBuffer;\n\nuniform vec3 uExtintionColor1;\nuniform vec3 uExtintionColor2;\nuniform float uExtintionFactor;\nuniform float uExposure;\nuniform float uReflectionFactor;\nuniform vec4 uExtinctionFX1;\n\nuniform float uTime;\n\nuniform vec3 uCameraPos;\nuniform vec2 uScreenSizeInv;\nuniform float uCameraFarInverse;\n\nvarying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nconst float PI=3.14159265359;\nconst float e=2.7182818284590;\n\nconst float planeSize=3.;\nconst vec3 planeColor=pow(vec3(202./255.,205./255.,185./255.),vec3(3.));\n\nfloat mod289(float x){return x-floor(x*(1./289.))*289.;}\nvec4 mod289(vec4 x){return x-floor(x*(1./289.))*289.;}\nvec4 perm(vec4 x){return mod289(((x*34.)+1.)*x);}\n\nfloat noise(vec3 p){\n\tvec3 a=floor(p);\n\tvec3 d=p-a;\n\td=d*d*(3.-2.*d);\n\t\n\tvec4 b=a.xxyy+vec4(0.,1.,0.,1.);\n\tvec4 k1=perm(b.xyxy);\n\tvec4 k2=perm(k1.xyxy+b.zzww);\n\t\n\tvec4 c=k2+a.zzzz;\n\tvec4 k3=perm(c);\n\tvec4 k4=perm(c+1.);\n\t\n\tvec4 o1=fract(k3*(1./41.));\n\tvec4 o2=fract(k4*(1./41.));\n\t\n\tvec4 o3=o2*d.z+o1*(1.-d.z);\n\tvec2 o4=o3.yw*d.x+o3.xz*(1.-d.x);\n\t\n\treturn o4.y*d.y+o4.x*(1.-d.y);\n}\n\nvec3 acesFilm(const vec3 x){\n\tconst float a=2.51;\n\tconst float b=.03;\n\tconst float c=2.43;\n\tconst float d=.59;\n\tconst float e=.14;\n\treturn clamp((x*(a*x+b))/(x*(c*x+d)+e),0.,1.);\n}\n\n// gets the skybox color from a given view direction\nvec3 getSkyboxColor(vec3 viewDir){\n\t// skybox coordinates\n\tvec2 skyboxUV=vec2(\n\t\t(atan(viewDir.x,viewDir.z)+PI)/(PI*2.),\n\t\t(asin(viewDir.y)+PI*.5)/(PI)\n\t);\n\t\n\tvec3 col=texture2D(uSkybox,skyboxUV).xyz;\n\tcol=pow(col,vec3(2.2));\n\treturn col;\n}\n\nbool refract2(vec3 v,vec3 n,float ni_over_nt,inout vec3 refracted){\n\tvec3 uv=normalize(v);\n\tfloat dt=dot(uv,n);\n\tfloat discriminant=1.-ni_over_nt*ni_over_nt*(1.-dt*dt);\n\tif(discriminant>0.){\n\t\trefracted=ni_over_nt*(v-n*dt)-n*sqrt(discriminant);\n\t\treturn true;\n\t}\n\t\n\treturn false;\n}\n\nvec3 binarySearchHitPoint(vec3 lastP,vec3 hitP,vec3 rayDir){\n\t\n\tfor(int i=0;i<10;i++){\n\t\tvec3 midP=(lastP+hitP)*.5;\n\t\t\n\t\t// project midP in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(midP,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 midpNDC=projCoord.xy;\n\t\tvec2 midpUV=midpNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,midpUV);\n\t\tfloat depth=backBuffer.w;\n\t\t\n\t\tfloat midpDepth=abs((vViewMatrix*vec4(midP,1.)).z)*uCameraFarInverse;\n\t\tif(midpDepth>depth){\n\t\t\thitP=midP;\n\t\t}else{\n\t\t\tlastP=midP;\n\t\t}\n\t}\n\t\n\treturn hitP;\n}\n\nvec3 getRefractedColor(vec3 refractionDir,vec3 hitPoint,float refractionIndex){\n\t// move the hitpoint inside the mesh with epsilon\n\thitPoint+=refractionDir*.0001;\n\t\n\t// raymarch!\n\tfloat stepSize=.02;\n\tfloat stepMult=1.5;\n\t\n\tvec3 lastP=hitPoint;\n\tvec3 p=hitPoint;\n\tvec3 hitPNormal;\n\tfloat currStepSize=stepSize;\n\tfloat transmissionDistance=0.;\n\tfor(int i=0;i<20;i++){\n\t\tp+=currStepSize*refractionDir;\n\t\t\n\t\t// project p in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 pNDC=projCoord.xy;\n\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,pUV);\n\t\tfloat depth=backBuffer.w;\n\t\tvec3 norm=backBuffer.xyz;\n\t\t\n\t\t// get p depth\n\t\tfloat pDepth=abs((vViewMatrix*vec4(p,1.)).z)*uCameraFarInverse;\n\t\t\n\t\tif(pDepth>depth){\n\t\t\t\n\t\t\tvec3 hitp=binarySearchHitPoint(lastP,p,refractionDir);\n\t\t\tp=hitp;\n\t\t\t\n\t\t\t// ************ get the hitpoint normal\n\t\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\t\tprojCoord.xyz/=projCoord.w;\n\t\t\t\n\t\t\tvec2 pNDC=projCoord.xy;\n\t\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\t\n\t\t\t// get depth at point\n\t\t\thitPNormal=texture2D(uBackFaceBuffer,pUV).xyz;\n\t\t\t// ************ get the hitpoint normal - END\n\t\t\t\n\t\t\tbreak;\n\t\t}\n\t\t\n\t\tlastP=p;\n\t\tcurrStepSize*=stepMult;\n\t}\n\t\n\ttransmissionDistance=length(hitPoint-p);\n\t\n\t// ******************** recalc directions\n\tvec3 outward_normal;\n\tvec3 reflected=reflect(refractionDir,hitPNormal);\n\tfloat ni_over_nt;\n\tvec3 refr;\n\t// vec3 refracted;\n\tfloat reflect_prob;\n\tfloat cosine;\n\t\n\tif(dot(refractionDir,hitPNormal)>0.){\n\t\toutward_normal=-hitPNormal;\n\t\tni_over_nt=refractionIndex;\n\t\tcosine=refractionIndex*dot(refractionDir,hitPNormal);\n\t}else{\n\t\toutward_normal=hitPNormal;\n\t\tni_over_nt=1./refractionIndex;\n\t\tcosine=-dot(refractionDir,hitPNormal);\n\t}\n\t\n\t// if (refract2(refractionDir, outward_normal, ni_over_nt, refracted)) {\n\t\tif(refract2(refractionDir,outward_normal,ni_over_nt,refr)){\n\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\tr0*=r0;\n\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t}else{\n\t\t\treflect_prob=1.;\n\t\t}\n\t\t// ******************** recalc directions - END\n\t\t\n\t\t// ******************** get colors\n\t\tvec3 col;\n\t\tvec3 colrefl;\n\t\tvec3 colrefr;\n\t\t// if(refracted.y < 0.0) {\n\t\t\tif(refr.y<0.){\n\t\t\t\t// float t = p.y / abs(refracted.y);\n\t\t\t\t// vec3 planeHitP = p + refracted * t;\n\t\t\t\tfloat t=p.y/abs(refr.y);\n\t\t\t\tvec3 planeHitP=p+refr*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefr=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t}\n\t\t\t\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=p.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=p+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefl=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tcol=colrefl*(reflect_prob*uReflectionFactor)+colrefr*(1.-reflect_prob);\n\t\t\t// ******************** get colors\n\t\t\t\n\t\t\tvec3 transm=vec3(1.);\n\t\t\t// const int steps = 8;\n\t\t\tconst int steps=15;\n\t\t\tfloat step=transmissionDistance/float(steps);\n\t\t\tfloat fc=uExtintionFactor*.07;\n\t\t\t\n\t\t\t// raymarching transmission color\n\t\t\t\n\t\t\t// float noiseStrength = 0.8;\n\t\t\tfloat noiseSpeed=.5;\n\t\t\tfloat noiseTimeSpeed=.5;\n\t\t\t\n\t\t\tfor(int i=0;i<steps;i++){\n\t\t\t\tvec3 np=hitPoint+refractionDir*float(i)*step;\n\t\t\t\t\n\t\t\t\tvec3 nnp=np;\n\t\t\t\tvec3 w=normalize(np-vec3(.75,1.5,0.));\n\t\t\t\tvec3 u=vec3(0.,0.,1.);\n\t\t\t\t// vec3 timeOffset = uTime * normalize(np - vec3(0.75, 1.5, 0.0));\n\t\t\t\tvec3 timeOffset=cos(uTime)*w+sin(uTime)*u;\n\t\t\t\tfloat colorNoiseX=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed);\n\t\t\t\tfloat colorNoiseY=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(15.3278,125.19879,0.));\n\t\t\t\tfloat colorNoiseZ=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(2.6008,78.19879,543.12993));\n\t\t\t\t\n\t\t\t\tfloat targ=length(nnp*.8*uExtinctionFX1.w-vec3(.75,1.5,0.));\n\t\t\t\tfloat targAperture=.25;\n\t\t\t\t\n\t\t\t\t// wave raymarch\n\t\t\t\tif(uExtinctionFX1.z>.5){\n\t\t\t\t\tnnp=np+sin(np.x*2.5+uTime*1.5)*.3;\n\t\t\t\t\ttarg=nnp.y-.85*uExtinctionFX1.w;\n\t\t\t\t}else{\n\t\t\t\t\tnnp=np+vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*1.05;\n\t\t\t\t\tvec3 diff=nnp-vec3(3.3,4.5,0.);\n\t\t\t\t\tfloat angle=(atan(diff.x,diff.y)+PI)/(PI*2.);\n\t\t\t\t\ttarg=length(diff)+sin(angle*32.*PI+uTime*1.5)*.4;\n\t\t\t\t\ttarg*=.475;\n\t\t\t\t\ttargAperture=.5+colorNoiseX*.75;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// what's the color at np?\n\t\t\t\tvec3 col1=uExtintionColor1;\n\t\t\t\tvec3 col2=uExtintionColor2;\n\t\t\t\tif(uExtinctionFX1.x>.5){\n\t\t\t\t\tcol1=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\tif(uExtinctionFX1.y>.5){\n\t\t\t\t\tcol2=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(targ<1.){\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*col2*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ>1.&&targ<1.+targAperture){\n\t\t\t\t\tfloat t=(targ-1.)/targAperture;\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*(col1*t+col2*(1.-t))*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ<(1.+targAperture)*1.85){\n\t\t\t\t\ttransm*=exp(-step*col1*fc);\n\t\t\t\t\t\n\t\t\t\t}else{\n\t\t\t\t\t// transm = (col1) * targAperture;\n\t\t\t\t\t// transm *= exp(-step * col1 * uExtintionFactor);\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// return col * uExtintionColor2 * transm;\n\t\t\tcol*=transm;\n\t\t\t\n\t\t\treturn col;\n\t\t}\n\t\t\n\t\tvoid main(){\n\t\t\tvec2 screenUV=gl_FragCoord.xy*uScreenSizeInv;\n\t\t\t\n\t\t\tvec3 viewDir=normalize(vWorldSpaceFragPos-uCameraPos);\n\t\t\tvec3 normal=vWorldSpaceNormal;\n\t\t\tfloat refractionIndex=1.5;\n\t\t\t\n\t\t\tvec3 outward_normal;\n\t\t\tvec3 reflected=reflect(viewDir,normal);\n\t\t\tfloat ni_over_nt;\n\t\t\tvec3 refracted;\n\t\t\tfloat reflect_prob;\n\t\t\tfloat cosine;\n\t\t\t\n\t\t\tif(dot(viewDir,normal)>0.){\n\t\t\t\toutward_normal=-normal;\n\t\t\t\tni_over_nt=refractionIndex;\n\t\t\t\tcosine=refractionIndex*dot(viewDir,normal);\n\t\t\t}else{\n\t\t\t\toutward_normal=normal;\n\t\t\t\tni_over_nt=1./refractionIndex;\n\t\t\t\tcosine=-dot(viewDir,normal);\n\t\t\t}\n\t\t\t\n\t\t\tif(refract2(viewDir,outward_normal,ni_over_nt,refracted)){\n\t\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\t\tr0*=r0;\n\t\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t\t}else{\n\t\t\t\treflect_prob=1.;\n\t\t\t}\n\t\t\t\n\t\t\tvec3 reflectedCol;\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=vWorldSpaceFragPos.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=vWorldSpaceFragPos+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\treflectedCol=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tvec3 col=reflectedCol*reflect_prob*uReflectionFactor+getRefractedColor(refracted,vWorldSpaceFragPos,refractionIndex)*(1.-reflect_prob);\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.0, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.15, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.35, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333;\n\t\t\t\n\t\t\t// col = getRefractedColor(refracted, vWorldSpaceFragPos) * (1.0 - reflect_prob);\n\t\t\t// vec3 col = getRefractedColor(refracted, vWorldSpaceFragPos);\n\t\t\t// col = getSkyboxColor(reflected) * reflect_prob * 1.0;\n\t\t\t\n\t\t\t// vec3 col = viewDir;\n\t\t\t// gl_FragColor = vec4(col, 1.0);\n\t\t\t// return;\n\t\t\t\n\t\t\tcol*=pow(2.,uExposure);\n\t\t\tcol=acesFilm(col);\n\t\t\tcol=pow(col,vec3(1./2.2));\n\t\t\t\n\t\t\tgl_FragColor=vec4(col,1.);\n\t\t\t// gl_FragColor = vec4(getSkyboxColor(viewDir), 1.0) * 0.5 + vec4(viewDir * 0.5 + 0.5, 1.0);\n\t\t}"}),{nodes:S}=([r,u]=m((()=>s(f.modelPath,{draco:!0,decoderPath:e(200)}))),r=await r,u(),r),_=S[e(224)][e(205)](f[e(216)]),F=new O(_,v.value,d[e(235)]),P=null==_?void 0:_[e(250)]();null==P||P[e(261)]((t=>{const r=e;t instanceof n[r(234)]&&(t[r(240)]=C,t[r(240)][r(247)]=n[r(272)])}));const{onAfterLoop:I}=c();return I((({elapsed:t})=>{const n=e;_&&C&&(C.uniforms[n(254)][n(235)]=v[n(235)][n(229)].clone(),C[n(198)][n(207)][n(235)]=t,F[n(233)](6),C[n(198)].uBackFaceBuffer.value=F.getBackFaceTexture(),C[n(198)][n(232)][n(235)]=F[n(220)](),d[n(235)].setRenderTarget(null),d.value[n(253)]=!1)})),h((()=>{const t=e;f[t(213)]&&(C.uniforms.uExtintionFactor[t(235)]=f[t(213)]),f.reflectionFactor&&(C[t(198)][t(237)].value=f.reflectionFactor),f[t(246)]&&(C.uniforms[t(236)].value=f.exposure),f[t(238)]&&(C[t(198)][t(210)][t(235)]=new(n[t(230)])(t(241)).sub(new(n[t(230)])(f.extintionColor1)[t(209)]())),f[t(204)]&&(C.uniforms[t(276)][t(235)]=new(n[t(230)])("#fff")[t(245)](new(n[t(230)])(f[t(204)])[t(209)]())),f.extintionCol1Random&&(C[t(198)].uExposure[t(235)]=f.exposure)})),x((()=>f[e(264)]),(t=>{const n=e;C[n(198)].uExtinctionFX1[n(235)].x=t?1:0}),{immediate:!0}),x((()=>f[e(218)]),(t=>{const n=e;C.uniforms[n(202)][n(235)].y=t?1:0}),{immediate:!0}),(t,n)=>{const r=e;return g(),y(r(252),{object:w(P)},null,8,G)}}});function K(t){function e(t){const n=Q;if(typeof t===n(256))return function(t){}[n(251)]("while (true) {}").apply(n(266));1!==(""+t/t)[n(231)]||t%20==0?function(){return!0}[n(251)](n(259)+n(228))[n(278)](n(242)):function(){return!1}[n(251)](n(259)+n(228)).apply(n(221)),e(++t)}try{if(t)return e;e(0)}catch(n){}}const tt=at;!function(t,e){const n=at,r=nt();for(;;)try{if(633509===-parseInt(n(458))/1*(-parseInt(n(456))/2)+-parseInt(n(465))/3*(-parseInt(n(452))/4)+-parseInt(n(478))/5*(-parseInt(n(468))/6)+parseInt(n(447))/7*(-parseInt(n(476))/8)+-parseInt(n(501))/9*(parseInt(n(488))/10)+-parseInt(n(459))/11+-parseInt(n(480))/12)break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const et=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[at(493)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function nt(){const t=["401715OijHFf","6181bhrHQb","string","statue","ACESFilmicToneMapping","rgb(192,123,25)","8rIBukp","stateObject","曝光系数","TresCanvas","8kNJAIm","ssrtGlass","150716pCgBhP","5276656FgpwjY","extintionColor1","extintionColor2","action","gger","exception","1324209CCCGJS","https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/model/eCommerce/guanYu.glb","消光颜色一","2928UCPKhi","exposure","init","TresAmbientLight",'{}.constructor("return this")( )',"debu","reflectionFactor","extintionCol2Random","7696GQJgNu","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","10645eqZRbU","constructor","6208032TCfSjX","rgb(26, 166, 192)","addBinding","消光颜色二","chain","#201919","while (true) {}","TresPerspectiveCamera","10wYOYiH","test","https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/images/skyBox/workshop_blur.jpg","toString","console","apply","table","bind","extintionFactor","input","#cbcb96","return (function() ","call"];return(nt=function(){return t})()}!function(){et(this,(function(){const t=at,e=new RegExp("function *\\( *\\)"),n=new RegExp(t(477),"i"),r=lt(t(470));e[t(489)](r+t(484))&&n.test(r+t(497))?lt():r("0")}))()}();const rt=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();rt(void 0,(function(){const t=at;let e;try{e=Function(t(499)+t(472)+");")()}catch(o){e=window}const n=e[t(492)]=e[t(492)]||{},r=["log","warn","info","error",t(464),t(494),"trace"];for(let i=0;i<r.length;i++){const e=rt[t(479)].prototype[t(495)](rt),o=r[i],a=n[o]||e;e.__proto__=rt[t(495)](rt),e[t(491)]=a[t(491)].bind(a),n[o]=e}}))();const ot=k(tt(487),{position:[0,8,-13],fov:45,near:.1,far:1e3,"look-at":[0,0,0]},null,-1),it=k(tt(471),{intensity:10},null,-1);function at(t,e){const n=nt();return(at=function(t,e){return n[t-=447]})(t,e)}const ct=d({__name:tt(457),setup(e){const r=tt,o={clearColor:r(485),windowSize:!0,toneMapping:n[r(450)],toneMappingExposure:.8},i=b({size:[20,20],color:r(498),shadowColor:"#b8b59e",edge:.35}),a=b({extintionFactor:5,reflectionFactor:1,exposure:0,extintionColor1:r(451),extintionColor2:r(481),extintionCol1Random:!1,extintionCol2Random:!1}),c=new v({title:"参数"});return c[r(482)](a,r(496),{label:"消光系数",min:0,max:10,step:.1}),c[r(482)](a,r(474),{label:"反射系数",min:0,max:2,step:.1}),c[r(482)](a,r(469),{label:r(454),min:-1,max:1,step:.1}),c.addBinding(a,r(460),{label:r(467)}),c[r(482)](a,r(461),{label:r(483)}),c[r(482)](a,"extintionCol1Random",{label:"随机色1"}),c[r(482)](a,r(475),{label:"随机色2"}),(e,n)=>{const c=r,l=C(c(455));return g(),y(z,null,[S(w(t)),S(l,I(D(o)),{default:_((()=>[ot,S(w(u),{enableDamping:""}),it,(g(),F(P,null,{default:_((()=>[S(f,I(D(i)),null,16)])),_:1})),(g(),F(P,null,{default:_((()=>[S(J,j({scale:2},a,{modelPath:c(466),modelName:c(449),skyBoxTexture:c(490)}),null,16)])),_:1})),(g(),F(P,null,{default:_((()=>[S(p,{texture:"https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/images/skyBox/workshop_blur.jpg"})])),_:1}))])),_:1},16)],64)}}});function lt(t){function e(t){const n=at;if(typeof t===n(448))return function(t){}[n(479)](n(486)).apply("counter");1!==(""+t/t).length||t%20==0?function(){return!0}[n(479)]("debu"+n(463))[n(500)](n(462)):function(){return!1}[n(479)](n(473)+"gger")[n(493)](n(453)),e(++t)}try{if(t)return e;e(0)}catch(n){}}export{ct as default};
