import{_ as t}from"./index.JehhujtP1735275234726.js";import{_ as e,q as n,p as r,m as o,C as i,z as a,ai as c}from"./three.jpi2UCEx1735275234726.js";import{m as s,e as l,b as u,a as f,U as p}from"./@tresjs.fCqPNEAw1735275234726.js";import{_ as v}from"./whiteFloorMesh.vue_vue_type_script_setup_true_lang.1YTtfnJA1735275234726.js";import{_ as d}from"./skyBoxAmesh.vue_vue_type_script_setup_true_lang.twMt4AcC1735275234726.js";import{P as m}from"./tweakpane.yHWGBmom1735275234726.js";import{d as h,a6 as g,a3 as x,w as y,o as w,D as b,u as C,r as S,e as _,j as P,g as F,J as I,f as z,al as D,aj as j,ak as k,m as E,F as N}from"./@vue.u2cBPEWn1735275234726.js";import"./index.cDMrDO9A1735275234726.js";import"./@fesjs.Okr_vpx41735275234726.js";import"./vue-router.bq4JfoTS1735275234726.js";import"./lodash-es.guXTxyfJ1735275234726.js";import"./@qlin.yHhFDldE1735275234726.js";import"./pinia.BXllYoho1735275234726.js";import"./vue-demi.C4xddsk91735275234726.js";import"./@floating-ui.BPbuo5Gx1735275234726.js";import"./@juggle.7yjBMqoW1735275234726.js";import"./chalk.w3XuUwyA1735275234726.js";/* empty css                                 */import"./iconify-icon.l-H2-fnN1735275234726.js";import"./@iconify.3mYF4lU71735275234726.js";import"./dompurify.rQUea5mq1735275234726.js";import"./@vueuse.8jEBPPFT1735275234726.js";import"./utils.p6vPEnfT1735275234726.js";import"./default.vue_vue_type_script_setup_true_lang.T3m2Qbnk1735275234726.js";import"./three-mesh-ui.module.WjskKMw01735275234726.js";!function(t,e){for(var n=T,r=B();;)try{if(151711===-parseInt(n(352))/1*(-parseInt(n(357))/2)+-parseInt(n(314))/3*(-parseInt(n(351))/4)+-parseInt(n(312))/5*(-parseInt(n(316))/6)+-parseInt(n(341))/7*(parseInt(n(344))/8)+parseInt(n(355))/9*(-parseInt(n(338))/10)+-parseInt(n(321))/11*(parseInt(n(347))/12)+parseInt(n(349))/13*(parseInt(n(354))/14))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();var M=function(){var t=!0;return function(e,n){var r=t?function(){if(n){var t=n[T(329)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();!function(){M(this,(function(){var t=T,e=new RegExp(t(342)),n=new RegExp("\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","i"),r=V(t(333));e[t(365)](r+t(323))&&n.test(r+t(324))?V():r("0")}))()}();var R=function(){var t=!0;return function(e,n){var r=t?function(){if(n){var t=n[T(329)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function B(){var t=["input","PlaneGeometry","gger","return (function() ","toString","apply","renderer","bind","Mesh","init","string","debu","uTexture","\n                uniform sampler2D uTexture;\n\n                varying vec2 vUv;\n\n                void main() {\n                    ","2530qBcfuF","action","ShaderMaterial","483hVNirY","function *\\( *\\)","warn","12416udyiZA","error","innerWidth","12OkXvoP","table","1940211isGjMS","info","4gDyHgE","190259IetYlZ","Scene","28hDRDHO","5769EBMuQH","material","2CIUkjZ","uniforms","prototype","__proto__","  \n                }","value","log","counter","test","while (true) {}","render","camera","mesh","call","5hXZktL","constructor","348459lyQKzD","exception","586650ZFxAWc","console","scene","trace","PerspectiveCamera","3098799cPmwpm","add","chain"];return(B=function(){return t})()}function T(t,e){var n=B();return(T=function(t,e){return n[t-=312]})(t,e)}R(void 0,(function(){var t,e=T;try{t=Function(e(327)+'{}.constructor("return this")( ));')()}catch(s){t=window}for(var n=t[e(317)]=t[e(317)]||{},r=[e(363),e(343),e(350),e(345),e(315),e(348),e(319)],o=0;o<r.length;o++){var i=R[e(313)][e(359)][e(331)](R),a=r[o],c=n[a]||i;i[e(360)]=R[e(331)](R),i[e(328)]=c[e(328)].bind(c),n[a]=i}}))();class W{constructor(t,n){var r=T;this.material=new(e[r(340)])({uniforms:{uTexture:{type:"t",value:null}},vertexShader:"\n                varying vec2 vUv;\n\n                void main() {\n                    vUv = uv;\n                    gl_Position = vec4(position.xy, 0.0, 1.0);    \n                }",fragmentShader:r(337)+(n||"gl_FragColor = texture2D(uTexture, vUv);")+r(361),depthTest:!1,depthWrite:!1}),this[r(369)]=new(e[r(332)])(new(e[r(325)])(2,2),this[r(356)]),this[r(368)]=new(e[r(320)])(45,window[r(346)]/window.innerHeight,1,1e3),this[r(330)]=t,this[r(318)]=new(e[r(353)]),this[r(318)][r(322)](this[r(369)])}blit(t,e){var n=T;this.renderer.setRenderTarget(e),this[n(356)][n(358)][n(336)][n(362)]=t,this[n(330)][n(367)](this[n(318)],this.camera),this[n(330)].setRenderTarget(null)}}function V(t){function e(t){var n=T;if(typeof t===n(334))return function(t){}[n(313)](n(366))[n(329)](n(364));1!==(""+t/t).length||t%20==0?function(){return!0}.constructor("debugger")[n(370)](n(339)):function(){return!1}[n(313)](n(335)+n(326))[n(329)]("stateObject"),e(++t)}try{if(t)return e;e(0)}catch(n){}}function H(t,e){const n=Z();return(H=function(t,e){return n[t-=416]})(t,e)}const X=H;!function(t,e){const n=H,r=Z();for(;;)try{if(632379===parseInt(n(440))/1+parseInt(n(435))/2*(parseInt(n(455))/3)+-parseInt(n(457))/4*(-parseInt(n(482))/5)+parseInt(n(418))/6*(-parseInt(n(475))/7)+-parseInt(n(425))/8*(-parseInt(n(480))/9)+parseInt(n(441))/10+-parseInt(n(442))/11*(parseInt(n(461))/12))break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const A=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n.apply(e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function Z(){const t=["1266324dDlXRP","uCameraFarInverse","toString","FrontSide","uniforms","prototype","call","value","function *\\( *\\)","apply","length","ShaderMaterial","autoClear","debu","21cCdntl","material","Mesh","uPrevDepth","FloatType","440541OosFNH","add","10JsACWl",'{}.constructor("return this")( )',"error","\n                uniform sampler2D uPrevDepth;\n                uniform float uCameraFarInverse;\n                uniform float uSample;\n                uniform vec2  uScreenSize;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n\n                    vec2 uv = gl_FragCoord.xy / uScreenSize;\n                    float prevRegisteredDepth = texture2D(uPrevDepth, uv).w;\n                    float currentDepth        = abs(vCameraSpacePos.z) * uCameraFarInverse;\n\n                    if(currentDepth <= prevRegisteredDepth) {\n                        discard;\n                    }\n\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }","traverse","clear","577062XrfXlp","mesh","resultBuffer","action","test","far","render","144EbYreX","exception","blitProgram","\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normal;\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }","texture","setRenderTarget","chain","log","getBackFaceTexture","ping","562wINcGE","frontFaceRT","__proto__","init","pong","283686WlSygT","4608010LgXDjM","275sFrlOK","DoubleSide","constructor","frontFaceMaterial","bind","counter","console","gger","scene","WebGLRenderTarget","info","return (function() ","camera","11478wNtFrw","Vector2","1716820tzEdvx","renderer","stateObject","compute"];return(Z=function(){return t})()}!function(){A(this,(function(){const t=H,e=new RegExp(t(469)),n=new RegExp("\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","i"),r=q(t(438));e[t(422)](r+t(431))&&n[t(422)](r+"input")?q():r("0")}))()}();const U=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[H(470)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();U(void 0,(function(){const t=H,e=function(){const t=H;let e;try{e=Function(t(453)+t(483)+");")()}catch(n){e=window}return e}(),n=e[t(448)]=e[t(448)]||{},r=[t(432),"warn",t(452),t(484),t(426),"table","trace"];for(let o=0;o<r[t(471)];o++){const e=U.constructor[t(466)][t(446)](U),i=r[o],a=n[i]||e;e[t(437)]=U.bind(U),e.toString=a[t(463)].bind(a),n[i]=e}}))();class O{constructor(t,i,a){const c=H;this[c(419)]=t.clone(),this[c(454)]=i,this.renderer=a,this[c(450)]=new n,this[c(450)][c(481)](this[c(419)]),this[c(427)]=new W(this[c(458)]),this.ping=new(e[c(451)])(innerWidth,innerHeight,{type:r,depthBuffer:!1,stencilBuffer:!1}),this.pong=new(e[c(451)])(innerWidth,innerHeight,{type:r,depthBuffer:!1,stencilBuffer:!1}),this[c(436)]=new(e[c(451)])(innerWidth,innerHeight,{type:e[c(479)]}),this[c(445)]=new o({uniforms:{uCameraFarInverse:{value:1/this.camera.far}},vertexShader:c(428),fragmentShader:"\n                uniform float uCameraFarInverse;\n\n                varying vec3 vWorldSpaceNormal;\n                varying vec3 vCameraSpacePos;\n\n                void main() {\n                    float currentDepth = abs(vCameraSpacePos.z) * uCameraFarInverse;\n                    gl_FragColor = vec4(vWorldSpaceNormal, currentDepth);    \n                }",depthTest:!0,depthWrite:!0,side:e[c(464)]}),this[c(476)]=new(e[c(472)])({uniforms:{uScreenSize:{value:new(e[c(456)])(innerWidth,innerHeight)},uPrevDepth:{type:"t",value:this[c(434)][c(429)]},uCameraFarInverse:{value:1/this[c(454)][c(423)]},uSample:{value:0}},vertexShader:"\n                varying vec3 vCameraSpacePos;\n                varying vec3 vWorldSpaceNormal;\n\n                void main() {\n                    vCameraSpacePos = (modelViewMatrix * vec4(position, 1.0)).xyz;\n                    vWorldSpaceNormal = normalize((modelMatrix * vec4(normal, 0.0)).xyz);\n\n                    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);    \n                }",fragmentShader:c(485),depthTest:!1,depthWrite:!1,side:e[c(443)]}),this[c(419)][c(416)]((t=>{const n=c;t instanceof e[n(477)]&&(t[n(476)]=this.material)}))}[X(460)](t){const n=X;this[n(458)][n(430)](this[n(434)]),this[n(458)][n(417)](),this[n(458)][n(430)](this[n(439)]),this.renderer.clear(),this.mesh[n(416)]((t=>{const r=n;t instanceof e[r(477)]&&(t[r(476)]=this.material)})),this[n(476)][n(465)][n(462)][n(468)]=1/this[n(454)][n(423)];for(let e=0;e<t;e++){let t=e%2==0?this.ping:this[n(439)],r=e%2==0?this[n(439)]:this[n(434)];this[n(476)][n(465)][n(478)][n(468)]=t[n(429)],this[n(476)][n(465)].uSample.value=e,this.renderer[n(473)]=!1,this[n(458)].setRenderTarget(r),this.renderer[n(424)](this[n(450)],this[n(454)]),this[n(458)][n(473)]=!0,this[n(427)].blit(r[n(429)],t)}t%2==0?this[n(420)]=this[n(434)]:this.resultBuffer=this[n(439)],this.mesh[n(416)]((t=>{t instanceof e[n(477)]&&(t.material=this.frontFaceMaterial)})),this[n(458)][n(430)](this[n(436)]),this.renderer[n(424)](this[n(450)],this[n(454)])}[X(433)](){const t=X;return this.resultBuffer[t(429)]}getFrontFaceTexture(){const t=X;return this[t(436)][t(429)]}}function q(t){function e(t){const n=H;if("string"==typeof t)return function(t){}[n(444)]("while (true) {}")[n(470)](n(447));1!==(""+t/t)[n(471)]||t%20==0?function(){return!0}[n(444)](n(474)+n(449))[n(467)](n(421)):function(){return!1}[n(444)](n(474)+n(449)).apply(n(459)),e(++t)}try{if(t)return e;e(0)}catch(n){}}const L=J;!function(t,e){const n=J,r=K();for(;;)try{if(506418===parseInt(n(231))/1*(parseInt(n(198))/2)+parseInt(n(181))/3+-parseInt(n(183))/4*(-parseInt(n(249))/5)+parseInt(n(244))/6+-parseInt(n(225))/7+-parseInt(n(202))/8*(-parseInt(n(165))/9)+-parseInt(n(191))/10)break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const G=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[J(193)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();!function(){G(this,(function(){const t=J,e=new RegExp(t(192)),n=new RegExp(t(169),"i"),r=tt("init");e.test(r+t(172))&&n.test(r+"input")?tt():r("0")}))()}();const Y=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[J(193)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();Y(void 0,(function(){const t=J;let e;try{e=Function(t(179)+t(246)+");")()}catch(o){e=window}const n=e[t(166)]=e[t(166)]||{},r=[t(227),t(187),t(245),t(230),t(171),t(185),t(218)];for(let i=0;i<r.length;i++){const e=Y.constructor[t(235)][t(229)](Y),o=r[i],a=n[o]||e;e[t(173)]=Y[t(229)](Y),e.toString=a.toString[t(229)](a),n[o]=e}}))();const $=[L(189)];function J(t,e){const n=K();return(J=function(t,e){return n[t-=164]})(t,e)}const Q=h({__name:L(176),props:{skyBoxTexture:{},modelPath:{},modelName:{},extintionFactor:{default:5},reflectionFactor:{default:1},exposure:{default:0},extintionColor1:{default:L(167)},extintionColor2:{default:L(186)},extintionCol1Random:{type:Boolean,default:!1},extintionCol2Random:{type:Boolean,default:!1}},async setup(t){const n=L;let r,o;const c=t,{map:p}=([r,o]=g((()=>u({map:c[n(232)]}))),r=await r,o(),r);p[n(210)]=e[n(211)],p[n(175)]=e[n(211)],p[n(224)]=e[n(228)],p[n(221)]=e[n(228)];const{camera:v,renderer:d,scene:m}=s(),h=new(e[n(190)])({uniforms:{uSkybox:{type:"t",value:p},uBackFaceBuffer:{type:"t",value:null},uFrontFaceBuffer:{type:"t",value:null},uCameraFarInverse:{value:1/v[n(247)][n(208)]},uScreenSizeInv:{value:new(e[n(201)])(1/window.innerWidth,1/window[n(212)])},uCameraPos:{value:new(e[n(219)])(0,0,0)},uTime:{value:0},uExtintionColor1:{value:new i(n(215))[n(200)](new(e[n(217)])(c[n(188)]).convertLinearToSRGB())},uExtintionColor2:{value:new(e[n(217)])(n(215))[n(200)](new(e[n(217)])(c[n(178)])[n(203)]())},uExtintionFactor:{value:c[n(248)]},uExposure:{value:c[n(240)]},uReflectionFactor:{value:c.reflectionFactor},uExtinctionFX1:{value:new(e[n(236)])(c.extintionCol1Random?1:0,c[n(174)]?1:0,0,1)}},vertexShader:"varying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\n// NOTE: we don't need the projViewModel matrix, because vWorldSpaceFragPos is already multiplied by the model matrix\n// I'm repeating this comment 5 times because I've lost 2 hours of my life debugging this thing\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nvoid main(){\n\t// NOTE: the multiplication with modelMatrix is required otherwise viewDir in the fragment shader would be incorrect\n\tvWorldSpaceFragPos=(modelMatrix*vec4(position,1.)).xyz;\n\tvWorldSpaceNormal=normalize((modelMatrix*vec4(normal,0.)).xyz);\n\t\n\tgl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.);\n\tvProjViewMatrix=projectionMatrix*viewMatrix;\n\tvViewMatrix=viewMatrix;\n}",fragmentShader:"uniform sampler2D uSkybox;\nuniform sampler2D uBackFaceBuffer;\nuniform sampler2D uFrontFaceBuffer;\n\nuniform vec3 uExtintionColor1;\nuniform vec3 uExtintionColor2;\nuniform float uExtintionFactor;\nuniform float uExposure;\nuniform float uReflectionFactor;\nuniform vec4 uExtinctionFX1;\n\nuniform float uTime;\n\nuniform vec3 uCameraPos;\nuniform vec2 uScreenSizeInv;\nuniform float uCameraFarInverse;\n\nvarying vec3 vWorldSpaceFragPos;\nvarying vec3 vWorldSpaceNormal;\nvarying mat4 vProjViewMatrix;\nvarying mat4 vViewMatrix;\n\nconst float PI=3.14159265359;\nconst float e=2.7182818284590;\n\nconst float planeSize=3.;\nconst vec3 planeColor=pow(vec3(202./255.,205./255.,185./255.),vec3(3.));\n\nfloat mod289(float x){return x-floor(x*(1./289.))*289.;}\nvec4 mod289(vec4 x){return x-floor(x*(1./289.))*289.;}\nvec4 perm(vec4 x){return mod289(((x*34.)+1.)*x);}\n\nfloat noise(vec3 p){\n\tvec3 a=floor(p);\n\tvec3 d=p-a;\n\td=d*d*(3.-2.*d);\n\t\n\tvec4 b=a.xxyy+vec4(0.,1.,0.,1.);\n\tvec4 k1=perm(b.xyxy);\n\tvec4 k2=perm(k1.xyxy+b.zzww);\n\t\n\tvec4 c=k2+a.zzzz;\n\tvec4 k3=perm(c);\n\tvec4 k4=perm(c+1.);\n\t\n\tvec4 o1=fract(k3*(1./41.));\n\tvec4 o2=fract(k4*(1./41.));\n\t\n\tvec4 o3=o2*d.z+o1*(1.-d.z);\n\tvec2 o4=o3.yw*d.x+o3.xz*(1.-d.x);\n\t\n\treturn o4.y*d.y+o4.x*(1.-d.y);\n}\n\nvec3 acesFilm(const vec3 x){\n\tconst float a=2.51;\n\tconst float b=.03;\n\tconst float c=2.43;\n\tconst float d=.59;\n\tconst float e=.14;\n\treturn clamp((x*(a*x+b))/(x*(c*x+d)+e),0.,1.);\n}\n\n// gets the skybox color from a given view direction\nvec3 getSkyboxColor(vec3 viewDir){\n\t// skybox coordinates\n\tvec2 skyboxUV=vec2(\n\t\t(atan(viewDir.x,viewDir.z)+PI)/(PI*2.),\n\t\t(asin(viewDir.y)+PI*.5)/(PI)\n\t);\n\t\n\tvec3 col=texture2D(uSkybox,skyboxUV).xyz;\n\tcol=pow(col,vec3(2.2));\n\treturn col;\n}\n\nbool refract2(vec3 v,vec3 n,float ni_over_nt,inout vec3 refracted){\n\tvec3 uv=normalize(v);\n\tfloat dt=dot(uv,n);\n\tfloat discriminant=1.-ni_over_nt*ni_over_nt*(1.-dt*dt);\n\tif(discriminant>0.){\n\t\trefracted=ni_over_nt*(v-n*dt)-n*sqrt(discriminant);\n\t\treturn true;\n\t}\n\t\n\treturn false;\n}\n\nvec3 binarySearchHitPoint(vec3 lastP,vec3 hitP,vec3 rayDir){\n\t\n\tfor(int i=0;i<10;i++){\n\t\tvec3 midP=(lastP+hitP)*.5;\n\t\t\n\t\t// project midP in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(midP,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 midpNDC=projCoord.xy;\n\t\tvec2 midpUV=midpNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,midpUV);\n\t\tfloat depth=backBuffer.w;\n\t\t\n\t\tfloat midpDepth=abs((vViewMatrix*vec4(midP,1.)).z)*uCameraFarInverse;\n\t\tif(midpDepth>depth){\n\t\t\thitP=midP;\n\t\t}else{\n\t\t\tlastP=midP;\n\t\t}\n\t}\n\t\n\treturn hitP;\n}\n\nvec3 getRefractedColor(vec3 refractionDir,vec3 hitPoint,float refractionIndex){\n\t// move the hitpoint inside the mesh with epsilon\n\thitPoint+=refractionDir*.0001;\n\t\n\t// raymarch!\n\tfloat stepSize=.02;\n\tfloat stepMult=1.5;\n\t\n\tvec3 lastP=hitPoint;\n\tvec3 p=hitPoint;\n\tvec3 hitPNormal;\n\tfloat currStepSize=stepSize;\n\tfloat transmissionDistance=0.;\n\tfor(int i=0;i<20;i++){\n\t\tp+=currStepSize*refractionDir;\n\t\t\n\t\t// project p in uv space\n\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\tprojCoord.xyz/=projCoord.w;\n\t\t\n\t\tvec2 pNDC=projCoord.xy;\n\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\n\t\t// get depth at point\n\t\tvec4 backBuffer=texture2D(uBackFaceBuffer,pUV);\n\t\tfloat depth=backBuffer.w;\n\t\tvec3 norm=backBuffer.xyz;\n\t\t\n\t\t// get p depth\n\t\tfloat pDepth=abs((vViewMatrix*vec4(p,1.)).z)*uCameraFarInverse;\n\t\t\n\t\tif(pDepth>depth){\n\t\t\t\n\t\t\tvec3 hitp=binarySearchHitPoint(lastP,p,refractionDir);\n\t\t\tp=hitp;\n\t\t\t\n\t\t\t// ************ get the hitpoint normal\n\t\t\tvec4 projCoord=vProjViewMatrix*vec4(p,1.);\n\t\t\tprojCoord.xyz/=projCoord.w;\n\t\t\t\n\t\t\tvec2 pNDC=projCoord.xy;\n\t\t\tvec2 pUV=pNDC*.5+.5;\n\t\t\t\n\t\t\t// get depth at point\n\t\t\thitPNormal=texture2D(uBackFaceBuffer,pUV).xyz;\n\t\t\t// ************ get the hitpoint normal - END\n\t\t\t\n\t\t\tbreak;\n\t\t}\n\t\t\n\t\tlastP=p;\n\t\tcurrStepSize*=stepMult;\n\t}\n\t\n\ttransmissionDistance=length(hitPoint-p);\n\t\n\t// ******************** recalc directions\n\tvec3 outward_normal;\n\tvec3 reflected=reflect(refractionDir,hitPNormal);\n\tfloat ni_over_nt;\n\tvec3 refr;\n\t// vec3 refracted;\n\tfloat reflect_prob;\n\tfloat cosine;\n\t\n\tif(dot(refractionDir,hitPNormal)>0.){\n\t\toutward_normal=-hitPNormal;\n\t\tni_over_nt=refractionIndex;\n\t\tcosine=refractionIndex*dot(refractionDir,hitPNormal);\n\t}else{\n\t\toutward_normal=hitPNormal;\n\t\tni_over_nt=1./refractionIndex;\n\t\tcosine=-dot(refractionDir,hitPNormal);\n\t}\n\t\n\t// if (refract2(refractionDir, outward_normal, ni_over_nt, refracted)) {\n\t\tif(refract2(refractionDir,outward_normal,ni_over_nt,refr)){\n\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\tr0*=r0;\n\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t}else{\n\t\t\treflect_prob=1.;\n\t\t}\n\t\t// ******************** recalc directions - END\n\t\t\n\t\t// ******************** get colors\n\t\tvec3 col;\n\t\tvec3 colrefl;\n\t\tvec3 colrefr;\n\t\t// if(refracted.y < 0.0) {\n\t\t\tif(refr.y<0.){\n\t\t\t\t// float t = p.y / abs(refracted.y);\n\t\t\t\t// vec3 planeHitP = p + refracted * t;\n\t\t\t\tfloat t=p.y/abs(refr.y);\n\t\t\t\tvec3 planeHitP=p+refr*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefr=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\t// colrefr = getSkyboxColor(refracted);\n\t\t\t\tcolrefr=getSkyboxColor(refr);\n\t\t\t}\n\t\t\t\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=p.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=p+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\tcolrefl=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\tcolrefl=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tcol=colrefl*(reflect_prob*uReflectionFactor)+colrefr*(1.-reflect_prob);\n\t\t\t// ******************** get colors\n\t\t\t\n\t\t\tvec3 transm=vec3(1.);\n\t\t\t// const int steps = 8;\n\t\t\tconst int steps=15;\n\t\t\tfloat step=transmissionDistance/float(steps);\n\t\t\tfloat fc=uExtintionFactor*.07;\n\t\t\t\n\t\t\t// raymarching transmission color\n\t\t\t\n\t\t\t// float noiseStrength = 0.8;\n\t\t\tfloat noiseSpeed=.5;\n\t\t\tfloat noiseTimeSpeed=.5;\n\t\t\t\n\t\t\tfor(int i=0;i<steps;i++){\n\t\t\t\tvec3 np=hitPoint+refractionDir*float(i)*step;\n\t\t\t\t\n\t\t\t\tvec3 nnp=np;\n\t\t\t\tvec3 w=normalize(np-vec3(.75,1.5,0.));\n\t\t\t\tvec3 u=vec3(0.,0.,1.);\n\t\t\t\t// vec3 timeOffset = uTime * normalize(np - vec3(0.75, 1.5, 0.0));\n\t\t\t\tvec3 timeOffset=cos(uTime)*w+sin(uTime)*u;\n\t\t\t\tfloat colorNoiseX=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed);\n\t\t\t\tfloat colorNoiseY=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(15.3278,125.19879,0.));\n\t\t\t\tfloat colorNoiseZ=noise(np*noiseSpeed+timeOffset*noiseTimeSpeed+vec3(2.6008,78.19879,543.12993));\n\t\t\t\t\n\t\t\t\tfloat targ=length(nnp*.8*uExtinctionFX1.w-vec3(.75,1.5,0.));\n\t\t\t\tfloat targAperture=.25;\n\t\t\t\t\n\t\t\t\t// wave raymarch\n\t\t\t\tif(uExtinctionFX1.z>.5){\n\t\t\t\t\tnnp=np+sin(np.x*2.5+uTime*1.5)*.3;\n\t\t\t\t\ttarg=nnp.y-.85*uExtinctionFX1.w;\n\t\t\t\t}else{\n\t\t\t\t\tnnp=np+vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*1.05;\n\t\t\t\t\tvec3 diff=nnp-vec3(3.3,4.5,0.);\n\t\t\t\t\tfloat angle=(atan(diff.x,diff.y)+PI)/(PI*2.);\n\t\t\t\t\ttarg=length(diff)+sin(angle*32.*PI+uTime*1.5)*.4;\n\t\t\t\t\ttarg*=.475;\n\t\t\t\t\ttargAperture=.5+colorNoiseX*.75;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// what's the color at np?\n\t\t\t\tvec3 col1=uExtintionColor1;\n\t\t\t\tvec3 col2=uExtintionColor2;\n\t\t\t\tif(uExtinctionFX1.x>.5){\n\t\t\t\t\tcol1=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\tif(uExtinctionFX1.y>.5){\n\t\t\t\t\tcol2=vec3(colorNoiseX,colorNoiseY,colorNoiseZ)*.85;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(targ<1.){\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*col2*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ>1.&&targ<1.+targAperture){\n\t\t\t\t\tfloat t=(targ-1.)/targAperture;\n\t\t\t\t\t\n\t\t\t\t\ttransm*=exp(-step*(col1*t+col2*(1.-t))*fc);\n\t\t\t\t\t\n\t\t\t\t}else if(targ<(1.+targAperture)*1.85){\n\t\t\t\t\ttransm*=exp(-step*col1*fc);\n\t\t\t\t\t\n\t\t\t\t}else{\n\t\t\t\t\t// transm = (col1) * targAperture;\n\t\t\t\t\t// transm *= exp(-step * col1 * uExtintionFactor);\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// return col * uExtintionColor2 * transm;\n\t\t\tcol*=transm;\n\t\t\t\n\t\t\treturn col;\n\t\t}\n\t\t\n\t\tvoid main(){\n\t\t\tvec2 screenUV=gl_FragCoord.xy*uScreenSizeInv;\n\t\t\t\n\t\t\tvec3 viewDir=normalize(vWorldSpaceFragPos-uCameraPos);\n\t\t\tvec3 normal=vWorldSpaceNormal;\n\t\t\tfloat refractionIndex=1.5;\n\t\t\t\n\t\t\tvec3 outward_normal;\n\t\t\tvec3 reflected=reflect(viewDir,normal);\n\t\t\tfloat ni_over_nt;\n\t\t\tvec3 refracted;\n\t\t\tfloat reflect_prob;\n\t\t\tfloat cosine;\n\t\t\t\n\t\t\tif(dot(viewDir,normal)>0.){\n\t\t\t\toutward_normal=-normal;\n\t\t\t\tni_over_nt=refractionIndex;\n\t\t\t\tcosine=refractionIndex*dot(viewDir,normal);\n\t\t\t}else{\n\t\t\t\toutward_normal=normal;\n\t\t\t\tni_over_nt=1./refractionIndex;\n\t\t\t\tcosine=-dot(viewDir,normal);\n\t\t\t}\n\t\t\t\n\t\t\tif(refract2(viewDir,outward_normal,ni_over_nt,refracted)){\n\t\t\t\tfloat r0=(1.-refractionIndex)/(1.+refractionIndex);\n\t\t\t\tr0*=r0;\n\t\t\t\treflect_prob=r0+(1.-r0)*pow((1.-cosine),5.);\n\t\t\t}else{\n\t\t\t\treflect_prob=1.;\n\t\t\t}\n\t\t\t\n\t\t\tvec3 reflectedCol;\n\t\t\tif(reflected.y<0.){\n\t\t\t\tfloat t=vWorldSpaceFragPos.y/abs(reflected.y);\n\t\t\t\tvec3 planeHitP=vWorldSpaceFragPos+reflected*t;\n\t\t\t\tif(abs(planeHitP.x)<planeSize&&abs(planeHitP.z)<planeSize){\n\t\t\t\t\treflectedCol=planeColor;\n\t\t\t\t}else{\n\t\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t\t}\n\t\t\t}else{\n\t\t\t\treflectedCol=getSkyboxColor(reflected);\n\t\t\t}\n\t\t\t\n\t\t\tvec3 col=reflectedCol*reflect_prob*uReflectionFactor+getRefractedColor(refracted,vWorldSpaceFragPos,refractionIndex)*(1.-reflect_prob);\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.0, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.15, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333 +\n\t\t\t// getRefractedColor(normalize(refracted + vec3(0.0, 0.35, 0.0)), vWorldSpaceFragPos) * (1.0 - reflect_prob) * 0.333;\n\t\t\t\n\t\t\t// col = getRefractedColor(refracted, vWorldSpaceFragPos) * (1.0 - reflect_prob);\n\t\t\t// vec3 col = getRefractedColor(refracted, vWorldSpaceFragPos);\n\t\t\t// col = getSkyboxColor(reflected) * reflect_prob * 1.0;\n\t\t\t\n\t\t\t// vec3 col = viewDir;\n\t\t\t// gl_FragColor = vec4(col, 1.0);\n\t\t\t// return;\n\t\t\t\n\t\t\tcol*=pow(2.,uExposure);\n\t\t\tcol=acesFilm(col);\n\t\t\tcol=pow(col,vec3(1./2.2));\n\t\t\t\n\t\t\tgl_FragColor=vec4(col,1.);\n\t\t\t// gl_FragColor = vec4(getSkyboxColor(viewDir), 1.0) * 0.5 + vec4(viewDir * 0.5 + 0.5, 1.0);\n\t\t}"}),{nodes:S}=([r,o]=g((()=>f(c[n(195)],{draco:!0,decoderPath:n(196)}))),r=await r,o(),r),_=S[n(237)][n(233)](c.modelName),P=new O(_,v.value,d[n(247)]),F=null==_?void 0:_[n(164)]();null==F||F[n(197)]((t=>{const r=n;t instanceof e[r(216)]&&(t.material=h,t[r(220)][r(213)]=a)}));const{onAfterLoop:I}=l();return I((({elapsed:t})=>{const e=n;_&&h&&(h.uniforms.uCameraPos[e(247)]=v[e(247)][e(214)].clone(),h.uniforms[e(205)][e(247)]=t,P.compute(6),h.uniforms[e(177)][e(247)]=P[e(239)](),h[e(222)][e(234)][e(247)]=P[e(223)](),d[e(247)][e(252)](null),d[e(247)].autoClear=!1)})),x((()=>{const t=n;c[t(248)]&&(h.uniforms[t(206)][t(247)]=c[t(248)]),c[t(184)]&&(h.uniforms[t(199)].value=c.reflectionFactor),c[t(240)]&&(h[t(222)][t(194)][t(247)]=c[t(240)]),c[t(188)]&&(h[t(222)][t(170)][t(247)]=new(e[t(217)])("#fff")[t(200)](new(e[t(217)])(c[t(188)])[t(203)]())),c[t(178)]&&(h[t(222)][t(207)][t(247)]=new(e[t(217)])(t(215)).sub(new i(c[t(178)])[t(203)]())),c[t(180)]&&(h[t(222)].uExposure[t(247)]=c[t(240)])})),y((()=>c[n(180)]),(t=>{const e=n;h[e(222)][e(209)][e(247)].x=t?1:0}),{immediate:!0}),y((()=>c[n(174)]),(t=>{const e=n;h.uniforms[e(209)].value.y=t?1:0}),{immediate:!0}),(t,e)=>{const r=n;return w(),b(r(243),{object:C(F)},null,8,$)}}});function K(){const t=["prototype","Vector4","Scene","stateObject","getBackFaceTexture","exposure","constructor","debu","primitive","1042902ezCICY","info",'{}.constructor("return this")( )',"value","extintionFactor","36915VMUZyi","string","while (true) {}","setRenderTarget","clone","382257EuJHWo","console","rgb(192,123,25)","counter","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","uExtintionColor1","exception","chain","__proto__","extintionCol2Random","wrapT","ssrtGlassMesh","uBackFaceBuffer","extintionColor2","return (function() ","extintionCol1Random","1091259rbrDmE","gger","56RUvnMH","reflectionFactor","table","rgb(26, 166, 192)","warn","extintionColor1","object","ShaderMaterial","6243270RzJpVE","function *\\( *\\)","apply","uExposure","modelPath","./draco/","traverse","472448PlJSXa","uReflectionFactor","sub","Vector2","184QwJKUc","convertLinearToSRGB","call","uTime","uExtintionFactor","uExtintionColor2","far","uExtinctionFX1","wrapS","ClampToEdgeWrapping","innerHeight","side","position","#fff","Mesh","Color","trace","Vector3","material","minFilter","uniforms","getFrontFaceTexture","magFilter","6716598SZSgcu","action","log","LinearMipmapLinearFilter","bind","error","2pbbnbr","skyBoxTexture","getObjectByName","uFrontFaceBuffer"];return(K=function(){return t})()}function tt(t){function e(t){const n=J;if(typeof t===n(250))return function(t){}[n(241)](n(251))[n(193)](n(168));1!==(""+t/t).length||t%20==0?function(){return!0}[n(241)](n(242)+n(182))[n(204)](n(226)):function(){return!1}[n(241)](n(242)+n(182))[n(193)](n(238)),e(++t)}try{if(t)return e;e(0)}catch(n){}}!function(t,e){const n=ot,r=rt();for(;;)try{if(188757===-parseInt(n(422))/1+-parseInt(n(380))/2*(parseInt(n(417))/3)+-parseInt(n(408))/4+parseInt(n(416))/5*(-parseInt(n(403))/6)+-parseInt(n(395))/7+-parseInt(n(427))/8*(-parseInt(n(397))/9)+parseInt(n(396))/10)break;r.push(r.shift())}catch(o){r.push(r.shift())}}();const et=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[ot(415)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();!function(){et(this,(function(){const t=ot,e=new RegExp("function *\\( *\\)"),n=new RegExp(t(412),"i"),r=at(t(392));e.test(r+t(388))&&n[t(405)](r+t(383))?at():r("0")}))()}();const nt=function(){let t=!0;return function(e,n){const r=t?function(){if(n){const t=n[ot(415)](e,arguments);return n=null,t}}:function(){};return t=!1,r}}();function rt(){const t=["extintionColor1","counter","length","289117jdZfbf","extintionColor2","随机色1","while (true) {}","call","9832lvaVXZ","reflectionFactor","string","https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/images/skyBox/workshop_blur.jpg","bind","error","extintionCol1Random","rgb(26, 166, 192)","console","6zXEsgR","rgb(192,123,25)","TresCanvas","input","#b8b59e","debu","warn","statue","chain","反射系数","toString","__proto__","init","https://opensource-1314935952.cos.ap-nanjing.myqcloud.com/model/eCommerce/guanYu.glb","消光颜色二","1793015IQFJzu","9877510miAlRU","2259MjbPgG",'{}.constructor("return this")( )',"log","曝光系数","消光颜色一","addBinding","804CzidII","constructor","test","extintionCol2Random","return (function() ","698908gRLtRu","gger","extintionFactor","trace","\\+\\+ *(?:[a-zA-Z_$][0-9a-zA-Z_$]*)","action","消光系数","apply","4315QrPtKw","271842qEbehF","exposure"];return(rt=function(){return t})()}function ot(t,e){const n=rt();return(ot=function(t,e){return n[t-=374]})(t,e)}nt(void 0,(function(){const t=ot,e=function(){const t=ot;let e;try{e=Function(t(407)+t(398)+");")()}catch(n){e=window}return e}(),n=e[t(379)]=e[t(379)]||{},r=[t(399),t(386),"info",t(376),"exception","table",t(411)];for(let o=0;o<r[t(421)];o++){const e=nt[t(404)].prototype[t(375)](nt),i=r[o],a=n[i]||e;e[t(391)]=nt[t(375)](nt),e.toString=a[t(390)][t(375)](a),n[i]=e}}))();const it=h({__name:"ssrtGlass",setup(e){const n=ot,r={clearColor:"#201919",windowSize:!0,toneMapping:c,toneMappingExposure:.8},o=S({size:[20,20],color:"#cbcb96",shadowColor:n(384),edge:.35}),i=S({extintionFactor:5,reflectionFactor:1,exposure:0,extintionColor1:n(381),extintionColor2:n(378),extintionCol1Random:!1,extintionCol2Random:!1}),a=new m({title:"参数"});return a[n(402)](i,n(410),{label:n(414),min:0,max:10,step:.1}),a[n(402)](i,n(428),{label:n(389),min:0,max:2,step:.1}),a[n(402)](i,n(418),{label:n(400),min:-1,max:1,step:.1}),a.addBinding(i,n(419),{label:n(401)}),a.addBinding(i,n(423),{label:n(394)}),a.addBinding(i,n(377),{label:n(424)}),a[n(402)](i,n(406),{label:"随机色2"}),(e,a)=>{const c=n,s=_(c(382));return w(),b(N,null,[P(C(t)),P(s,j(k(r)),{default:F((()=>[a[0]||(a[0]=I("TresPerspectiveCamera",{position:[0,8,-13],fov:45,near:.1,far:1e3,"look-at":[0,0,0]},null,-1)),P(C(p),{enableDamping:""}),a[1]||(a[1]=I("TresAmbientLight",{intensity:10},null,-1)),(w(),z(D,null,{default:F((()=>[P(v,j(k(o)),null,16)])),_:1})),(w(),z(D,null,{default:F((()=>[P(Q,E({scale:2},i,{modelPath:c(393),modelName:c(387),skyBoxTexture:c(374)}),null,16)])),_:1})),(w(),z(D,null,{default:F((()=>[P(d,{texture:c(374)})])),_:1}))])),_:1},16)],64)}}});function at(t){function e(t){const n=ot;if(typeof t===n(429))return function(t){}[n(404)](n(425)).apply(n(420));1!==(""+t/t)[n(421)]||t%20==0?function(){return!0}[n(404)]("debu"+n(409))[n(426)](n(413)):function(){return!1}[n(404)](n(385)+"gger")[n(415)]("stateObject"),e(++t)}try{if(t)return e;e(0)}catch(n){}}export{it as default};
